{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we present the implementation and the empirical study of 'L-SAGA' : our proposed learning hyper-heuristic for the flowhsop permutation problem (FPP). It uses a simulated annealing algorithm for the top level equipped with a novel add-on learning component, and an adaptation of the genetic algorithm for the FPP for the bottom level.\n",
    "\n",
    "The implementation code is first presented, then tested on each of the taillard instances benchmark.The obtained make-spans are compared with those of our implementation of the genetic algorithm for flowhsop, simulated annealing, and the 3 dedicated heuristics of Palmer, CDS and NEH."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ycondabase\\envs\\aivenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "import heuristics\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class to hold a taillard instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inst:\n",
    "    def __init__(self, jobs: int, machines: int, seed: int, ub: int, lb: int, matrix: list[list[int]]):\n",
    "        \"\"\"\n",
    "        Represents an instance of the scheduling problem.\n",
    "        \n",
    "        Args:\n",
    "            jobs (int): Number of jobs.\n",
    "            machines (int): Number of machines.\n",
    "            seed (int): Seed for random number generation.\n",
    "            ub (int): Upper bound.\n",
    "            lb (int): Lower bound.\n",
    "            matrix (list[list[int]]): Matrix representing job durations on machines.\n",
    "        \"\"\"\n",
    "        self.jobs = jobs\n",
    "        self.machines = machines\n",
    "        self.seed = seed\n",
    "        self.ub = ub\n",
    "        self.lb = lb\n",
    "        self.matrix = matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load the instances of a taillard configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tai(nb_jobs, nb_machines):\n",
    "    with open(f\"content/tai{nb_jobs}_{nb_machines}.txt\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    instances: list[Inst] = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        params = [int(e) for e in lines[i+1].split()]\n",
    "        jobs = params[0]\n",
    "        machines = params[1]\n",
    "        seed = params[2]\n",
    "        ub = params[3]\n",
    "        lb = params[4]\n",
    "\n",
    "        matrix = [[int(e) for e in line.strip().split()] for line in lines[i+3:i+3+machines]]\n",
    "        instances.append(Inst(jobs, machines, seed, ub, lb, matrix))\n",
    "        i+=3+machines\n",
    "    \n",
    "    return instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podium Bank data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PodiumBank:\n",
    "    def __init__(self, size=10):\n",
    "        #the bank is sorted in an ascendant manner of the make span\n",
    "        self.bank = list()\n",
    "        self.size = size\n",
    "\n",
    "    \n",
    "    def insert(self, ms_hps): #make_span hyper_parameter_state tuple\n",
    "        if len(self.bank) == 0:\n",
    "            self.bank.append(ms_hps)\n",
    "        else:\n",
    "            insertion_index = -1\n",
    "            for i in range(len(self.bank)):\n",
    "                if ms_hps[0]<self.bank[i][0]:\n",
    "                    insertion_index = i\n",
    "            if insertion_index != -1:\n",
    "                self.bank = self.bank[:i] + [ms_hps] + self.bank[i:self.size-1]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([1,2,3,4]).discard(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 3, 5, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {1:2, 3:4, 5:6}\n",
    "d[0] = 8\n",
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_jobs = 20\n",
    "k_mms = (0.01, 0.1, 0.01)\n",
    "k_values = [int(nb_jobs * (k_mms[0]+i*k_mms[2])) for i in range(int((k_mms[1]-k_mms[0])/k_mms[2])+1)]\n",
    "list(set(k_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSAGA:\n",
    "    def __init__(self,\n",
    "                 tai_inst:Inst,\n",
    "                 init_type=['cds', 'palmer', 'neh', 'heuristics', 'heuristics_random', 'full_random'],\n",
    "                 selection_type=['roulette', 'rank', 'elitist', 'tournament', 'random'],\n",
    "                 crossover_type=['uniform', 'k_points'],\n",
    "                 replacement_type=['best_all', 'parents_replaced_by_offspring', 'worst_population_replaced_by_offspring', 'best_between_parents_and_offspring', 'roulette', 'rank', 'elitist', 'tournament', 'random'],\n",
    "                 population_size_mms=(20,50,5), #min_max_step\n",
    "                 pool_size_mms=(0.1, 0.9, 0.1),\n",
    "                 crossover_rate_mms=(0.1, 0.9, 0.1),\n",
    "                 mutation_rate_mms=(0.1, 0.9, 0.1),\n",
    "                 num_iterations_mms=(200, 600, 100),\n",
    "                 max_stagnation_mms=(50, 200, 50),\n",
    "                 k_points_mms=(0.1, 0.9, 0.1),\n",
    "                 variety_degree=1,\n",
    "                 num_hyper_params_neigh_window=1, #numeric hyper-parameters neighboring window size\n",
    "                 cat_neigh_ratio=0.4,\n",
    "                 podium_banck_size=10\n",
    "                ):\n",
    "        self.tai_inst = tai_inst\n",
    "        self.jobs_list = self.get_instance(tai_inst)\n",
    "        self.nb_jobs = len(self.jobs_list)\n",
    "        self.nb_machines = len(self.jobs_list[0])\n",
    "        self.hps_star = None\n",
    "        self.seq_star = None\n",
    "        self.make_span_star = None\n",
    "        self.hyper_params = {\n",
    "            'init_type': init_type,\n",
    "            'selection_type': selection_type,\n",
    "            'crossover_type': crossover_type,\n",
    "            'replacement_type': replacement_type,\n",
    "            'population_size': [i for i in range(population_size_mms[0], population_size_mms[1]+1, population_size_mms[2])],\n",
    "            'pool_size': [pool_size_mms[0]+i*pool_size_mms[2] for i in range(int((pool_size_mms[1]-pool_size_mms[0])/pool_size_mms[2])+1)],\n",
    "            'crossover_rate': [crossover_rate_mms[0]+crossover_rate_mms[2]*i for i in range(int((crossover_rate_mms[1]-crossover_rate_mms[0])/crossover_rate_mms[2])+1)],\n",
    "            'mutation_rate': [mutation_rate_mms[0]+mutation_rate_mms[2]*i for i in range(int((mutation_rate_mms[1]-mutation_rate_mms[0])/mutation_rate_mms[2])+1)],\n",
    "            'num_iterations': [i for i in range(num_iterations_mms[0], num_iterations_mms[1]+1, num_iterations_mms[2])],\n",
    "            'max_stagnation': [i for i in range(max_stagnation_mms[0],max_stagnation_mms[1]+1,max_stagnation_mms[2])],\n",
    "        }\n",
    "        s = set(\n",
    "                [int((self.nb_jobs-1) * (0.01+i*0.01)) for i in range(10)]+ #exploring the hundredths\n",
    "                [int((self.nb_jobs-1) * (k_points_mms[0]+i*k_points_mms[2])) for i in range(int((k_points_mms[1]-k_points_mms[0])/k_points_mms[2])+1)] #exploruing above tenths\n",
    "            )\n",
    "        s.discard(0)\n",
    "        self.hyper_params['k_points'] =  list(s)\n",
    "        self.cat_hyper_params = ['init_type', 'selection_type', 'crossover_type', 'replacement_type']\n",
    "        self.num_hyper_params = ['population_size', 'pool_size', 'crossover_rate', 'mutation_rate', 'num_iterations', 'max_stagnation', 'k_points']\n",
    "        self.variable_params = [key for key in self.hyper_params.keys() if self.hyper_params[key][0] != self.hyper_params[key][-1]]\n",
    "        if variety_degree > len(self.variable_params): raise Exception(\"variety_degree > len(self.variable_params)\")\n",
    "        self.variety_degree = variety_degree\n",
    "        self.num_hyper_params_neigh_window = num_hyper_params_neigh_window\n",
    "        self.cat_neigh_ratio = cat_neigh_ratio\n",
    "        self.podium_bank = PodiumBank(size=podium_banck_size)\n",
    "        self.neh_res = heuristics.NEH(self.tai_inst)()\n",
    "        self.cds_res = heuristics.cds_heuristic(np.array(self.jobs_list))\n",
    "        self.palmer_res = heuristics.Palmer(self.jobs_list).optim()\n",
    "\n",
    "        #stats\n",
    "        self.nb_podium_bank_usage = 0\n",
    "        self.nb_deteriorations = 0\n",
    "        self.nb_jumps = 0\n",
    "        self.hps_star_trace = []\n",
    "        self.current_make_span_trace = []\n",
    "\n",
    "\n",
    "    # utility functions for the low level genetic algorithm\n",
    "\n",
    "    def get_instance(self, tai_inst: Inst):\n",
    "        # Extract the jobs list from the given instance\n",
    "        \n",
    "        jobs_list = []\n",
    "        for i in range(len(tai_inst.matrix[0])):\n",
    "            jobs_list.append([])\n",
    "            for j in range(len(tai_inst.matrix)):\n",
    "                jobs_list[-1].append(tai_inst.matrix[j][i])\n",
    "        return jobs_list\n",
    "\n",
    "    def cumulate(self, job: list, previous_cumul=None):\n",
    "        # Calculate the cumulative completion times for a job\n",
    "        \n",
    "        res = [0] * len(job)\n",
    "        if previous_cumul == None:\n",
    "            res[0] = job[0]\n",
    "            for i in range(1, len(job)):\n",
    "                res[i] = res[i - 1] + job[i]\n",
    "        else:\n",
    "            res[0] = previous_cumul[0] + job[0]\n",
    "            for i in range(1, len(job)):\n",
    "                res[i] = max(res[i - 1], previous_cumul[i]) + job[i]\n",
    "        return res\n",
    "\n",
    "    def cumulate_seq(self, seq: list):\n",
    "        # Calculates the cumulative time for a sequence of jobs on machines.\n",
    "\n",
    "        cumulated = None\n",
    "        for i in seq:\n",
    "            cumulated = self.cumulate(self.jobs_list[i], cumulated)\n",
    "        return cumulated\n",
    "\n",
    "    def evaluate_makespan(self, schedule):\n",
    "        # Evaluates the makespan (completion time) of a given schedule.\n",
    "\n",
    "        cumulative = self.cumulate_seq(schedule)\n",
    "        return cumulative[-1]\n",
    " \n",
    "    def initialize_population(self, init_type, population_size):\n",
    "        \"\"\"\n",
    "        Initializes the population of individuals.\n",
    "        \n",
    "        Args:\n",
    "            init_type (str): Type of initialization method.\n",
    "            population_size (int): Size of the population.\n",
    "            \n",
    "        Returns:\n",
    "            list: Initialized population of individuals.\n",
    "        \"\"\"\n",
    "        \n",
    "        def perturb_sequence(sequence):\n",
    "            \"\"\"\n",
    "            Perturbs a sequence by swapping two random jobs.\n",
    "            \n",
    "            Args:\n",
    "                sequence (list): Sequence of jobs.\n",
    "                \n",
    "            Returns:\n",
    "                list: Perturbed sequence.\n",
    "            \"\"\"\n",
    "            perturbed_seq = sequence[:]\n",
    "            for _ in range(2):\n",
    "                i, j = random.sample(range(len(perturbed_seq)), 2)\n",
    "                perturbed_seq[i], perturbed_seq[j] = perturbed_seq[j], perturbed_seq[i]\n",
    "            return perturbed_seq\n",
    "\n",
    "        population = []\n",
    "        \n",
    "        if init_type == \"cds\":\n",
    "            cds_seq, _ = self.cds_res#heuristics.cds_resheuristic(np.array(self.jobs_list))\n",
    "            population.append(cds_seq)\n",
    "            for _ in range(population_size - 1):\n",
    "                perturbed_seq = perturb_sequence(cds_seq)\n",
    "                population.append(perturbed_seq)\n",
    "\n",
    "        elif init_type == \"palmer\":\n",
    "            palmer_seq, _ = self.palmer_res#heuristics.Palmer(self.jobs_list).optim()\n",
    "            population.append(palmer_seq)\n",
    "            for _ in range(population_size - 1):\n",
    "                perturbed_seq = perturb_sequence(palmer_seq)\n",
    "                population.append(perturbed_seq)\n",
    "\n",
    "        elif init_type == \"neh\":\n",
    "            _, neh_seq = self.neh_res#heuristics.NEH(self.tai_inst)()\n",
    "            population.append(neh_seq)\n",
    "            for _ in range(population_size - 1):\n",
    "                perturbed_seq = perturb_sequence(neh_seq)\n",
    "                population.append(perturbed_seq)\n",
    "\n",
    "        elif init_type == \"heuristics\":\n",
    "            cds_size = population_size // 3\n",
    "            palmer_size = population_size // 3\n",
    "            neh_size = population_size - cds_size - palmer_size\n",
    "            \n",
    "            for _ in range(cds_size):\n",
    "                cds_seq, _ = self.cds_res#heuristics.cds_heuristic(np.array(self.jobs_list))\n",
    "                population.append(perturb_sequence(cds_seq))\n",
    "            \n",
    "            for _ in range(palmer_size):\n",
    "                palmer_seq, _ = self.palmer_res#heuristics.Palmer(self.jobs_list).optim()\n",
    "                population.append(perturb_sequence(palmer_seq))\n",
    "            \n",
    "            for _ in range(neh_size):\n",
    "                _, neh_seq = self.neh_res#heuristics.NEH(self.tai_inst)()\n",
    "                population.append(perturb_sequence(neh_seq))\n",
    "\n",
    "        elif init_type == \"heuristics_random\":\n",
    "\n",
    "            cds_seq, _ = self.cds_res#heuristics.cds_heuristic(np.array(self.jobs_list))\n",
    "            population.append(perturb_sequence(cds_seq))\n",
    "\n",
    "            palmer_seq, _ = self.palmer_res#heuristics.Palmer(self.jobs_list).optim()\n",
    "            population.append(perturb_sequence(palmer_seq))\n",
    "\n",
    "            _, neh_seq = self.neh_res#heuristics.NEH(self.tai_inst)()\n",
    "            population.append(perturb_sequence(neh_seq))\n",
    "\n",
    "            for _ in range(population_size - 3):\n",
    "                random_seq = random.sample(range(self.nb_jobs), self.nb_jobs)\n",
    "                population.append(random_seq)\n",
    "\n",
    "        elif init_type == \"full_random\":\n",
    "\n",
    "            for _ in range(population_size):\n",
    "                random_seq = random.sample(range(self.nb_jobs), self.nb_jobs)\n",
    "                population.append(random_seq)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid initialization type\")\n",
    "\n",
    "        return population\n",
    "  \n",
    "    def select_parents(self, population):\n",
    "        \"\"\"\n",
    "        Selects parents from the population using tournament selection.\n",
    "        \n",
    "        Args:\n",
    "            population (list): Population of individuals.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Pair of selected parents.\n",
    "        \"\"\"\n",
    "        tournament = random.sample(population, 3)\n",
    "        tournament.sort(key=lambda x: self.evaluate_makespan(x))\n",
    "        return tournament[0], tournament[1]\n",
    "  \n",
    "    def crossover(self, crossover_type, parent1, parent2, crossover_rate, k_points=None):\n",
    "        \"\"\"\n",
    "        Performs crossover between two parents to produce offspring.\n",
    "        \n",
    "        Args:\n",
    "            crossover_type (str): Type of crossover operation.\n",
    "            parent1 (list): First parent.\n",
    "            parent2 (list): Second parent.\n",
    "            crossover_rate (float): Rate of crossover.\n",
    "            k (int, optional): Parameter for k-point crossover. Defaults to None.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Pair of offspring.\n",
    "        \"\"\"\n",
    "\n",
    "        def ensure_each_job_once(offspring):\n",
    "            \"\"\"\n",
    "            Ensures each job appears exactly once in the offspring.\n",
    "            \n",
    "            Args:\n",
    "                offspring (list): Offspring sequence.\n",
    "            \"\"\"\n",
    "            # Ensure offspring contains each job exactly once\n",
    "            job_count = {job: 0 for job in range(self.nb_jobs)}\n",
    "            for job in offspring:\n",
    "                job_count[job] += 1\n",
    "            for i, job in enumerate(offspring):\n",
    "                if job_count[job] > 1:\n",
    "                    for swap_job, count in job_count.items():\n",
    "                        if count == 0:\n",
    "                            offspring[i] = swap_job\n",
    "                            job_count[swap_job] += 1\n",
    "                            job_count[job] -= 1\n",
    "                            break\n",
    "\n",
    "        if random.random() < crossover_rate:\n",
    "            \n",
    "            if crossover_type == 'uniform':\n",
    "                k = None\n",
    "                mask = [random.choice([0, 1]) for _ in range(len(parent1))]\n",
    "                offspring1 = [gene1 if bit else gene2 for gene1, gene2, bit in zip(parent1, parent2, mask)]\n",
    "                offspring2 = [gene1 if bit else gene2 for gene1, gene2, bit in zip(parent2, parent1, mask)]\n",
    "\n",
    "            else:\n",
    "                if k_points is None or k_points < 1:\n",
    "                    raise ValueError(\"k must be >= 1 for one_point, two_points, and k_points crossovers\")\n",
    "                \n",
    "                if k_points is not None and k_points >= self.nb_jobs:\n",
    "                    raise ValueError(\"k in crossover must be less than the number of jobs\")\n",
    "\n",
    "                if ((crossover_type == 'one_point') or (k_points == 1)):\n",
    "                    k = 1\n",
    "                    points = [random.randint(1, len(parent1) - 1)]\n",
    "\n",
    "                elif ((crossover_type == 'two_points') or (k_points == 2)):\n",
    "                    k = 2\n",
    "                    points = sorted(random.sample(range(1, len(parent1)), 2))\n",
    "\n",
    "                elif crossover_type == 'k_points':\n",
    "                    points = sorted(random.sample(range(1, len(parent1)), k_points))\n",
    "\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid crossover type\")\n",
    "\n",
    "                offspring1, offspring2 = parent1[:], parent2[:]\n",
    "                switch = False\n",
    "                for i in range(len(parent1)):\n",
    "                    if i in points:\n",
    "                        switch = not switch\n",
    "                    if switch:\n",
    "                        offspring1[i], offspring2[i] = offspring2[i], offspring1[i]\n",
    "\n",
    "            ensure_each_job_once(offspring1)\n",
    "            ensure_each_job_once(offspring2)\n",
    "            return offspring1, offspring2\n",
    "        \n",
    "        else:\n",
    "            return parent1[:], parent2[:]\n",
    "\n",
    "    def mutate(self, solution, mutation_rate):\n",
    "        \"\"\"\n",
    "        Mutates a solution with a given mutation rate.\n",
    "        \n",
    "        Args:\n",
    "            solution (list): Solution to mutate.\n",
    "            mutation_rate (float): Rate of mutation.\n",
    "            \n",
    "        Returns:\n",
    "            list: Mutated solution.\n",
    "        \"\"\"\n",
    "        if random.random() < mutation_rate:\n",
    "            i, j = random.sample(range(len(solution)), 2)\n",
    "            solution[i], solution[j] = solution[j], solution[i]\n",
    "        return solution\n",
    "\n",
    "    def select_reproduction_pool(self, selection_type, population, pool_size):\n",
    "        \"\"\"\n",
    "        Selects a pool of individuals for reproduction.\n",
    "        \n",
    "        Args:\n",
    "            selection_type (str): Type of selection method.\n",
    "            population (list): Population of individuals.\n",
    "            pool_size (int): Size of the pool.\n",
    "            \n",
    "        Returns:\n",
    "            list: Pool of selected individuals.\n",
    "        \"\"\"\n",
    "        \n",
    "        chosen = []\n",
    "\n",
    "        if selection_type == \"roulette\":\n",
    "            total_fitness = sum(self.evaluate_makespan(ind) for ind in population)\n",
    "            selection_probs = [self.evaluate_makespan(ind) / total_fitness for ind in population]\n",
    "            chosen = random.choices(population, weights=selection_probs, k=pool_size)\n",
    "\n",
    "        elif selection_type == \"rank\":\n",
    "            population_sorted = sorted(population, key=self.evaluate_makespan)\n",
    "            ranks = range(1, len(population_sorted) + 1)\n",
    "            total_rank = sum(ranks)\n",
    "            rank_weights = [rank / total_rank for rank in ranks]\n",
    "            chosen = random.choices(population_sorted, weights=rank_weights, k=pool_size)\n",
    "\n",
    "        elif selection_type == \"elitist\":\n",
    "            population_sorted = sorted(population, key=self.evaluate_makespan)\n",
    "            chosen = population_sorted[:pool_size]\n",
    "\n",
    "        elif selection_type == \"tournament\":\n",
    "            for _ in range(pool_size):\n",
    "                contenders = random.sample(population, 3)\n",
    "                chosen.append(min(contenders, key=self.evaluate_makespan))\n",
    "\n",
    "        elif selection_type == \"random\":\n",
    "            chosen = random.sample(population, pool_size)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Invalid type\")\n",
    "\n",
    "        return chosen\n",
    "  \n",
    "    def replace_population(self, replacement_type, population, parents, offspring, population_size):\n",
    "        \"\"\"\n",
    "        Replaces the population with new individuals.\n",
    "        \n",
    "        Args:\n",
    "            replacement_type (str): Type of replacement method.\n",
    "            population (list): Current population.\n",
    "            parents (list): Parents generated during reproduction.\n",
    "            offspring (list): Offspring generated during reproduction.\n",
    "            population_size (int): Size of the population.\n",
    "            \n",
    "        Returns:\n",
    "            list: New population.\n",
    "        \"\"\"\n",
    "        \n",
    "        def select_population(selection_type, population, pool_size):\n",
    "            \"\"\"\n",
    "            Selects individuals for the next population.\n",
    "            \n",
    "            Args:\n",
    "                selection_type (str): Type of selection method.\n",
    "                population (list): Population of individuals.\n",
    "                pool_size (int): Size of the selection pool.\n",
    "                \n",
    "            Returns:\n",
    "                list: Selected individuals for the next population.\n",
    "            \"\"\"\n",
    "            return self.select_reproduction_pool(selection_type, population, pool_size)\n",
    "\n",
    "        if replacement_type == \"best_all\":\n",
    "            combined_population = population + offspring\n",
    "            combined_population.sort(key=lambda x: self.evaluate_makespan(x))\n",
    "            return combined_population[:population_size]\n",
    "\n",
    "        elif replacement_type == \"parents_replaced_by_offspring\":\n",
    "            population_without_parents = [ind for ind in population if ind not in parents]\n",
    "            return population_without_parents + offspring\n",
    "\n",
    "        elif replacement_type == \"worst_population_replaced_by_offspring\":\n",
    "            population_sorted = sorted(population, key=self.evaluate_makespan)\n",
    "            population_without_worst = population_sorted[:-len(offspring)]\n",
    "            return population_without_worst + offspring\n",
    "\n",
    "        elif replacement_type == \"best_between_parents_and_offspring\":\n",
    "            population_without_parents = [ind for ind in population if ind not in parents]\n",
    "            combined_sub_population = sorted(parents + offspring, key=self.evaluate_makespan)\n",
    "            return population_without_parents + combined_sub_population[:len(parents)]\n",
    "        \n",
    "        else:\n",
    "            return select_population(replacement_type, population + offspring, len(population))\n",
    "\n",
    "    def genetic_algorithm(self, init_type, selection_type, crossover_type, replacement_type, population_size, pool_size, crossover_rate, mutation_rate, num_iterations, max_stagnation, k_points=None):\n",
    "        \"\"\"\n",
    "        Executes the Genetic Algorithm to find the best solution.\n",
    "        \n",
    "        Args:\n",
    "            init_type (str): Type of initialization method.\n",
    "            selection_type (str): Type of parent selection method.\n",
    "            crossover_type (str): Type of crossover method.\n",
    "            replacement_type (str): Type of population replacement method.\n",
    "            population_size (int): Size of the population.\n",
    "            pool_size (int): Size of the reproduction pool.\n",
    "            crossover_rate (float): Rate of crossover.\n",
    "            mutation_rate (float): Rate of mutation.\n",
    "            num_iterations (int): Maximum number of iterations.\n",
    "            max_stagnation (int): Maximum number of iterations without improvement.\n",
    "            k_points (int, optional): Parameter for k-point crossover. Defaults to None.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Best solution and its makespan.\n",
    "        \"\"\"\n",
    "        \n",
    "        if pool_size > population_size:\n",
    "            raise ValueError(\"Pool size must be less than population size.\")\n",
    "\n",
    "        population = self.initialize_population(init_type, population_size)\n",
    "        population.sort(key=lambda x: self.evaluate_makespan(x))\n",
    "        \n",
    "        best_solution = population[0]\n",
    "        best_solution_fitness = self.evaluate_makespan(best_solution)\n",
    "        stagnation_count = 0\n",
    "\n",
    "        for i in range(num_iterations):\n",
    "            reproduction_pool = self.select_reproduction_pool(selection_type, population, pool_size)\n",
    "            offspring = []\n",
    "            parents = []\n",
    "\n",
    "            for _ in range(pool_size // 2):\n",
    "                parent1, parent2 = self.select_parents(reproduction_pool)\n",
    "                parents.extend([parent1, parent2])\n",
    "                child1, child2 = self.crossover(crossover_type, parent1, parent2, crossover_rate, k_points) \n",
    "                child1 = self.mutate(child1, mutation_rate)\n",
    "                child2 = self.mutate(child2, mutation_rate)\n",
    "                offspring.extend([child1, child2])\n",
    "\n",
    "            population = self.replace_population(replacement_type, population, parents, offspring, population_size)\n",
    "            population.sort(key=lambda x: self.evaluate_makespan(x))\n",
    "\n",
    "            current_best_solution = population[0]\n",
    "            current_best_solution_fitness = self.evaluate_makespan(current_best_solution)\n",
    "\n",
    "            if current_best_solution_fitness < best_solution_fitness:\n",
    "                best_solution = current_best_solution\n",
    "                best_solution_fitness = current_best_solution_fitness\n",
    "                stagnation_count = 0\n",
    "            else:\n",
    "                stagnation_count += 1\n",
    "\n",
    "            if max_stagnation is not None and stagnation_count >= max_stagnation:\n",
    "                break\n",
    "\n",
    "        return best_solution\n",
    "\n",
    "    # utility functions for the high level simulated annealing\n",
    "\n",
    "    def init_random_hps(self):\n",
    "        hps={\n",
    "            'init_type':np.random.choice(self.hyper_params['init_type']),\n",
    "            'selection_type':np.random.choice(self.hyper_params['selection_type']),\n",
    "            'crossover_type':np.random.choice(self.hyper_params['crossover_type']),\n",
    "            'replacement_type':np.random.choice(self.hyper_params['replacement_type']),\n",
    "            'population_size':np.random.choice(self.hyper_params['population_size']),\n",
    "            'pool_size':np.random.choice(self.hyper_params['pool_size']),\n",
    "            'crossover_rate':np.random.choice(self.hyper_params['crossover_rate']),\n",
    "            'mutation_rate':np.random.choice(self.hyper_params['mutation_rate']),\n",
    "            'num_iterations':np.random.choice(self.hyper_params['num_iterations']),\n",
    "            'max_stagnation':np.random.choice(self.hyper_params['max_stagnation']),\n",
    "            'k_points':np.random.choice(self.hyper_params['k_points'])\n",
    "        }\n",
    "        return hps\n",
    "    \n",
    "    def cartesian_product(self, possible_values, keys): #the list of possible values for each dimension\n",
    "        products = [{keys[0]:value} for value in possible_values[0]]\n",
    "        for dimension_values, key in zip(possible_values[1:], keys[1:]):    \n",
    "            new_products = []\n",
    "            for product in products:\n",
    "                for value in dimension_values:\n",
    "                    new_product = dict(product)\n",
    "                    new_product[key] = value\n",
    "                    new_products.append(new_product)\n",
    "            products = new_products\n",
    "        return products\n",
    "\n",
    "    def measure_hps_dist(self, hps1, hps2):\n",
    "        dist = 0\n",
    "        for hyper_param in self.cat_hyper_params:\n",
    "            dist +=  (1 if hps1[hyper_param] == hps2[hyper_param] else 0) # * relevance_coeff ...! \n",
    "        for hyper_param in self.num_hyper_params:\n",
    "            if hyper_param not in self.variable_params: continue\n",
    "            dist += abs(hps1[hyper_param] - hps2[hyper_param]) / (self.hyper_params[hyper_param][-1] - self.hyper_params[hyper_param][0]) # * relevance_coeff ...!\n",
    "        return dist\n",
    "\n",
    "    def get_podium_score(self,neigh):\n",
    "        score = 0\n",
    "        tot_podium_make_spans = sum([1/(ms_champion[0]) for ms_champion in self.podium_bank.bank])\n",
    "        for make_span, champion in self.podium_bank.bank:\n",
    "            score += math.exp(-self.measure_hps_dist(neigh, champion)) * ((1/(make_span))/tot_podium_make_spans)\n",
    "        return score\n",
    "\n",
    "    def generate_neigh_hps(self, hps, T, beta):\n",
    "        #randomly selecting 'self.variety_degree' hyper_parameters to forcibly vary, the rest of the hyper_params can either vary or not\n",
    "        varied_keys = np.random.choice([key for key in self.variable_params], self.variety_degree, replace=False)\n",
    "        #we create the neighbor hps possible values for each hyper parameter\n",
    "        neigh_hps_values = []\n",
    "        #for each categorical hyper-param\n",
    "        for hyper_param in self.cat_hyper_params:\n",
    "            #if the hyper param is to be forcibly varied\n",
    "            if hyper_param in varied_keys:\n",
    "                neigh_space = list(self.hyper_params[hyper_param])\n",
    "                neigh_space.remove(hps[hyper_param])\n",
    "                neigh_hps_values.append(np.random.choice(neigh_space, int(self.cat_neigh_ratio * len(neigh_space)+1), replace=False))\n",
    "            else:\n",
    "                neigh_hps_values.append(np.random.choice(self.hyper_params[hyper_param], int(self.cat_neigh_ratio * len(self.hyper_params[hyper_param]))+1, replace=False))\n",
    "        #for each numercial hyper-param\n",
    "        for hyper_param in self.num_hyper_params:\n",
    "            # we get its index in the range of possible values\n",
    "            hyper_param_value_index = self.hyper_params[hyper_param].index(hps[hyper_param])\n",
    "            # we get the bottom index of the neighboring window using self.num_hyper_param_neigh_windows\n",
    "            win_bottom_index = hyper_param_value_index-self.num_hyper_params_neigh_window\n",
    "            # we check if we didn't go below 0\n",
    "            if win_bottom_index < 0: win_bottom_index = 0\n",
    "            # we create the neighboring space\n",
    "            neigh_space = self.hyper_params[hyper_param][win_bottom_index : hyper_param_value_index+self.num_hyper_params_neigh_window+1]\n",
    "            if hyper_param in varied_keys:\n",
    "                neigh_space.remove(hps[hyper_param])\n",
    "                neigh_hps_values.append(neigh_space)\n",
    "            else:\n",
    "                neigh_hps_values.append(neigh_space)\n",
    "\n",
    "        #we check if the temperature is still high ==> we are still in full exploration\n",
    "        if ( self.podium_bank.size == 0 ) or ( np.random.random() < math.exp(-(1/(beta*T))) ):\n",
    "            neighbor = {key:np.random.choice(neigh_hps_values[i]) for i, key in enumerate(self.hyper_params.keys())}\n",
    "            #neighbor = random.sample(neighbors, 1)[0]\n",
    "        #else we use the podium\n",
    "        else:\n",
    "            self.nb_podium_bank_usage += 1\n",
    "            #we generate all the possible neighbors by doing the cartesian product of the neigh values for the different dimensions \n",
    "            neighbors = self.cartesian_product(neigh_hps_values, self.cat_hyper_params + self.num_hyper_params)\n",
    "            #we affect podium scores to the neighbors\n",
    "            neigh_podium_scores = []\n",
    "            for neigh in neighbors:\n",
    "                neigh_podium_scores.append(self.get_podium_score(neigh))\n",
    "            #we randomly select the new neighbor using the podium_scores as weights\n",
    "            p = np.array(neigh_podium_scores)\n",
    "            p = p / np.sum(p)\n",
    "            neighbor = np.random.choice(neighbors, p=p)\n",
    "        return neighbor\n",
    "\n",
    "    def optim(self,\n",
    "              T=1.0,\n",
    "              T_min=0.001,\n",
    "              alpha=0.9,\n",
    "              beta=10,\n",
    "              nb_iter=100,\n",
    "              length_palier=1,\n",
    "              jump_rate=0,\n",
    "              jump_ratio=1,\n",
    "              debug=False,\n",
    "              trace=False):\n",
    "        #checking for hyper_params coherance\n",
    "        # if jump_rate != 0 and jump_ratio>=1/alpha:\n",
    "        #     raise Exception(\"Y_exception: jump_ratio >= 1/alpha\")\n",
    "        #initializing the hyper_parameter_state hps randomly and computing the corresponding make_span_star\n",
    "        loc_hps_star = hps = self.init_random_hps()\n",
    "        ga_params = dict(hps)\n",
    "        ga_params['pool_size'] = int(ga_params['pool_size'] * ga_params['population_size'])\n",
    "        if (ga_params['pool_size']<=2) : ga_params['pool_size'] = 3\n",
    "        print(f\"Executing initial GA with {ga_params['num_iterations']} iterations\")\n",
    "        loc_seq_star = current_seq = self.genetic_algorithm(**ga_params)\n",
    "        loc_make_span_star = current_make_span = self.evaluate_makespan(current_seq)\n",
    "        #inserting the first hps in the podium bank\n",
    "        self.podium_bank.insert((current_make_span, hps))\n",
    "        #showing some debug\n",
    "        if debug:\n",
    "            print('initial hps', hps)\n",
    "            print('initial make_span', current_make_span)\n",
    "        #preping the tracing\n",
    "        if trace:\n",
    "            self.hps_star_trace.append(loc_hps_star)\n",
    "            self.current_make_span_trace.append(current_make_span)\n",
    "        #we initialize the temperature session at length_palier\n",
    "        temp_session = length_palier\n",
    "        #main loop\n",
    "        for _ in (t := tqdm(range(nb_iter))):\n",
    "            #generate a random neighbour sequence\n",
    "            new_hps = self.generate_neigh_hps(hps, T, beta)\n",
    "            #compute the energy difference\n",
    "            ga_params = dict(new_hps)\n",
    "            ga_params['pool_size'] = int(ga_params['pool_size'] * ga_params['population_size'])\n",
    "            t.set_description(f\"Temperature {T}, GA {ga_params['num_iterations'] } iters\")\n",
    "            if (ga_params['pool_size']<=2) : ga_params['pool_size'] = 3\n",
    "            neigh_seq = self.genetic_algorithm(**ga_params)\n",
    "            neigh_make_span = self.evaluate_makespan(neigh_seq)\n",
    "            delta = current_make_span - neigh_make_span\n",
    "            #if the neighbour sequence is better, accept it\n",
    "            if delta >= 0:\n",
    "                hps = new_hps\n",
    "                current_seq = neigh_seq\n",
    "                current_make_span = neigh_make_span\n",
    "                #we insert the new hps and its makespan into the podium bank\n",
    "                self.podium_bank.insert((current_make_span, hps))\n",
    "                # we check if the newly obtained solution is better than the current best\n",
    "                if current_make_span < loc_make_span_star:\n",
    "                    loc_hps_star = hps\n",
    "                    loc_seq_star = current_seq\n",
    "                    loc_make_span_star = current_make_span\n",
    "                    if trace:\n",
    "                        self.hps_star_trace.append(loc_hps_star)\n",
    "            #if the neighbour sequence is worse, accept it with a probability that decreases with the temperature\n",
    "            elif np.random.random() < math.exp((delta)/(beta*T)):\n",
    "                    self.nb_deteriorations += 1\n",
    "                    hps = new_hps\n",
    "                    current_seq = neigh_seq\n",
    "                    current_make_span = neigh_make_span\n",
    "                    #we insert the new hps and its makespan into the podium bank\n",
    "                    self.podium_bank.insert((current_make_span, hps))\n",
    "            #cooling\n",
    "            temp_session -= 1\n",
    "            if temp_session == 0:\n",
    "                if np.random.random() < jump_rate:\n",
    "                    self.nb_jumps += 1\n",
    "                    T = T * jump_ratio\n",
    "                else:\n",
    "                    T = T * alpha\n",
    "                temp_session = length_palier\n",
    "            if trace:\n",
    "                self.current_make_span_trace.append(current_make_span)\n",
    "            if(T<=T_min): break\n",
    "        self.hps_star = loc_hps_star\n",
    "        self.seq_star = loc_seq_star\n",
    "        self.make_span_star = loc_make_span_star   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstration on a small instance with strong hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing initial GA with 400 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Temperature 0.009349612773224767, GA 500 iters: 100%|██████████| 150/150 [06:19<00:00,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_span_star 1360\n",
      "hps_star {'init_type': 'heuristics', 'selection_type': 'rank', 'crossover_type': 'k_points', 'replacement_type': 'best_between_parents_and_offspring', 'population_size': 35, 'pool_size': 0.6, 'crossover_rate': 0.4, 'mutation_rate': 0.4, 'num_iterations': 400, 'max_stagnation': 150, 'k_points': 3}\n",
      "nb_podium_bank_usage 24\n",
      "nb_deteriorations 32\n",
      "nb_jumps 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1287590dcd0>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tai_inst = load_tai(20, 5)\n",
    "hh = LSAGA(tai_inst[1],\n",
    "           variety_degree=5,\n",
    "           num_hyper_params_neigh_window=2, #numeric hyper-parameters neighboring window size\n",
    "           cat_neigh_ratio=0.4,\n",
    "           podium_banck_size=5)\n",
    "hh.optim(T=1,\n",
    "         T_min=0.001,\n",
    "         alpha=0.9, # decay factor\n",
    "         beta=100, # exploration factor\n",
    "         nb_iter=150,\n",
    "         length_palier=3,\n",
    "         jump_rate=0.05,\n",
    "         jump_ratio=1.15,\n",
    "         trace=True)\n",
    "print('make_span_star', hh.make_span_star)\n",
    "print('hps_star', hh.hps_star)\n",
    "print('nb_podium_bank_usage', hh.nb_podium_bank_usage)\n",
    "print('nb_deteriorations', hh.nb_deteriorations)\n",
    "print('nb_jumps', hh.nb_jumps)\n",
    "plt.plot(range(1, len(hh.current_make_span_trace)+1), hh.current_make_span_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to execute the neh, cds and palmer heuristics for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_heur(instances):\n",
    "    cds = []\n",
    "    palmer = []\n",
    "    neh = []\n",
    "    for instance in instances:\n",
    "        def get_instance(tai_inst:Inst):\n",
    "                jobs_list = []\n",
    "                for i in range(len(tai_inst.matrix[0])):\n",
    "                    jobs_list.append([])\n",
    "                    for j in range(len(tai_inst.matrix)):\n",
    "                        jobs_list[-1].append(tai_inst.matrix[j][i])\n",
    "                return jobs_list\n",
    "        jobs_list = get_instance(instance)\n",
    "        \n",
    "        cds.append(heuristics.cds_heuristic(np.array(jobs_list))[1])\n",
    "        \n",
    "        palmer.append(heuristics.Palmer(jobs_list).optim()[1])\n",
    "\n",
    "        neh.append(heuristics.NEH(instance)()[0])\n",
    "        \n",
    "    return cds, palmer, neh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to execute simulated annealing alone for comparison (with hyper param tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulatedAnnealing:\n",
    "    def __init__(self, tai_inst:Inst):\n",
    "        def get_instance(tai_inst:Inst):\n",
    "            jobs_list = []\n",
    "            for i in range(len(tai_inst.matrix[0])):\n",
    "                jobs_list.append([])\n",
    "                for j in range(len(tai_inst.matrix)):\n",
    "                    jobs_list[-1].append(tai_inst.matrix[j][i])\n",
    "            return jobs_list\n",
    "        self.tai_inst = tai_inst\n",
    "        self.jobs_list = get_instance(tai_inst)\n",
    "        self.nb_jobs = len(self.jobs_list)\n",
    "        self.nb_machines = len(self.jobs_list[0])\n",
    "        self.seq_star = None\n",
    "        self.make_span_star = None\n",
    "\n",
    "    # utility function that returns the gantt cumule based on a job execution times and a previous gantt cumule\n",
    "    def cumulate(self, job:list, previous_cumul=None):\n",
    "        res = [0] * len(job)\n",
    "\n",
    "        if(previous_cumul==None):\n",
    "            res[0] = job[0]\n",
    "            for i in range(1, len(job)):\n",
    "                res[i] = res[i-1] + job[i]\n",
    "        else:\n",
    "            res[0] = previous_cumul[0] + job[0]\n",
    "            for i in range(1, len(job)):\n",
    "                res[i] = max(res[i-1], previous_cumul[i]) + job[i]\n",
    "\n",
    "        return res\n",
    "\n",
    "    # utility function that computes the gantt cumule given only a job sequence (not used in the algorithm due to inneficiency\n",
    "    # dynamic programming with cumulate is used instead ...)\n",
    "    def cumulate_seq(self, seq:list):\n",
    "        cumulated = None\n",
    "        for i in seq:\n",
    "            cumulated = self.cumulate(self. jobs_list[i], cumulated)\n",
    "        return cumulated\n",
    "\n",
    "\n",
    "    #launching the optimization\n",
    "    def optim(self, debug=False, T=1.0, T_min=0.0001, alpha=0.9, nb_iter=10000, init_method='random', neigh_method='full', length_palier=1, jump_rate=0, jump_ratio=1.): \n",
    "        #making sure the jump ratio is not greater that the 1/alpha\n",
    "        if jump_rate != 0 and jump_ratio>=1/alpha:\n",
    "            raise Exception(\"Y_exception: jump_ratio >= 1/alpha\")\n",
    "        #initialize the current sequence and its make span\n",
    "        if init_method == 'random':\n",
    "            seq = np.random.choice(np.arange(0,self.nb_jobs), size=self.nb_jobs, replace=False)\n",
    "            make_span = self.cumulate_seq(seq)[-1]\n",
    "        elif init_method == 'palmer':\n",
    "            palmer = heuristics.Palmer(self.jobs_list)\n",
    "            seq, make_span = palmer.optim()\n",
    "        elif init_method == 'cds':\n",
    "            seq, make_span = heuristics.cds_heuristic(np.array(self.jobs_list))\n",
    "        else:#neh\n",
    "            make_span, seq = heuristics.NEH(self.tai_inst)()\n",
    "\n",
    "        #initialize the iteration counter\n",
    "        it = 1\n",
    "\n",
    "        #initialize the best sequence and its make span\n",
    "        self.seq_star = copy.deepcopy(seq)\n",
    "        self.make_span_star = make_span\n",
    "\n",
    "        #we initialize the temperature session at length_palier\n",
    "        temp_session = length_palier\n",
    "        #main loop\n",
    "        while T > T_min and it<=nb_iter:\n",
    "            #generate a random neighbour sequence\n",
    "            if neigh_method == 'full':\n",
    "                i, j = np.random.choice(np.arange(self.nb_jobs), size=2, replace=False)\n",
    "                seq_neigh = copy.deepcopy(seq)\n",
    "                seq_neigh[i], seq_neigh[j] = seq_neigh[j], seq_neigh[i]\n",
    "            else:#next\n",
    "                i = np.random.randint(0 , self.nb_jobs-1)\n",
    "                seq_neigh = copy.deepcopy(seq)\n",
    "                seq_neigh[i], seq_neigh[i+1] = seq_neigh[i+1], seq_neigh[i]\n",
    "                \n",
    "            #compute the make span of the neighbour sequence\n",
    "            make_span_neigh = self.cumulate_seq(seq_neigh)[-1]\n",
    "\n",
    "            #compute the energy difference\n",
    "            delta = make_span - make_span_neigh\n",
    "\n",
    "            #if the neighbour sequence is better, accept it\n",
    "            if delta > 0:\n",
    "                seq = copy.deepcopy(seq_neigh)\n",
    "                make_span = make_span_neigh\n",
    "                self.seq_star = copy.deepcopy(seq)\n",
    "                self.make_span_star = make_span\n",
    "\n",
    "            #if the neighbour sequence is worse, accept it with a probability that decreases with the temperature\n",
    "            else:\n",
    "                if random.random() < math.exp(delta/T):\n",
    "                    seq = copy.deepcopy(seq_neigh)\n",
    "                    make_span = make_span_neigh\n",
    "\n",
    "            #cooling\n",
    "            temp_session -= 1\n",
    "            if temp_session == 0:\n",
    "                if random.random() < jump_rate:\n",
    "                    T = T * jump_ratio\n",
    "                else:\n",
    "                    T = T * alpha\n",
    "                temp_session = length_palier\n",
    "\n",
    "            #incrementing it\n",
    "            it += 1\n",
    "            \n",
    "            #debug\n",
    "            if debug:\n",
    "                print(\"Iteration: \", it)\n",
    "                print(\"Temperature: \", T)\n",
    "                print(\"Sequence: \", seq)\n",
    "                print(\"Make span: \", make_span)\n",
    "            \n",
    "        return self.make_span_star, self.seq_star\n",
    "\n",
    "def exec_sa(instances, n_trials=10):\n",
    "\n",
    "    studies = []\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "    for i, instance in enumerate(instances):\n",
    "        study = optuna.create_study()\n",
    "        sa = SimulatedAnnealing(instance)\n",
    "        \n",
    "        def objective(trial):\n",
    "            T = trial.suggest_float(\"T\", 1, 10, step=1)\n",
    "            T_min = trial.suggest_categorical(\"T_min\", [0.001, 0.0001, 0.00001])\n",
    "            alpha = trial.suggest_float(\"alpha\", 0.5, 0.95, step=0.05)\n",
    "            nb_iter = trial.suggest_categorical(\"nb_iter\", [1000, 10000, 20000])\n",
    "            init_method = trial.suggest_categorical(\"init_method\", ['random', 'palmer', 'neh'])\n",
    "            neigh_method = trial.suggest_categorical(\"neigh_method\", ['full', 'next'])\n",
    "            length_palier = trial.suggest_categorical(\"length_palier\", [1, 5, 10, 20])\n",
    "            jump_rate = trial.suggest_categorical(\"jump_rate\", [0, 0.05, 0.1, 0.2])\n",
    "            jump_ratio = trial.suggest_categorical(\"jump_ratio\", [1.01, 1.03, 1.05])\n",
    "\n",
    "            return sa.optim(alpha=alpha, T=T, T_min=T_min, nb_iter=nb_iter, init_method=init_method, neigh_method=neigh_method, length_palier=length_palier, jump_rate=jump_rate, jump_ratio=jump_ratio)[0]\n",
    "\n",
    "        study.optimize(objective, n_trials, show_progress_bar=True)\n",
    "        studies.append(copy.deepcopy(study))\n",
    "\n",
    "    return studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to execute the genetic algorithm for comparison (with hyper param tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAlgorithm:\n",
    "    def __init__(self, tai_inst: Inst):\n",
    "        # Initializes the Genetic Algorithm with a given instance of the scheduling problem.\n",
    "        \n",
    "        self.tai_inst = tai_inst\n",
    "        self.jobs_list = self.get_instance(tai_inst)\n",
    "        self.nb_jobs = len(self.jobs_list)\n",
    "        self.nb_machines = len(self.jobs_list[0])\n",
    "        self.seq_star = None\n",
    "        self.make_span_star = None\n",
    "\n",
    "        \n",
    "    def get_instance(self, tai_inst: Inst):\n",
    "        # Extract the jobs list from the given instance\n",
    "        \n",
    "        jobs_list = []\n",
    "        for i in range(len(tai_inst.matrix[0])):\n",
    "            jobs_list.append([])\n",
    "            for j in range(len(tai_inst.matrix)):\n",
    "                jobs_list[-1].append(tai_inst.matrix[j][i])\n",
    "        return jobs_list\n",
    "\n",
    "    \n",
    "    def cumulate(self, job: list, previous_cumul=None):\n",
    "        # Calculate the cumulative completion times for a job\n",
    "            \n",
    "        res = [0] * len(job)\n",
    "        if previous_cumul == None:\n",
    "            res[0] = job[0]\n",
    "            for i in range(1, len(job)):\n",
    "                res[i] = res[i - 1] + job[i]\n",
    "        else:\n",
    "            res[0] = previous_cumul[0] + job[0]\n",
    "            for i in range(1, len(job)):\n",
    "                res[i] = max(res[i - 1], previous_cumul[i]) + job[i]\n",
    "        return res\n",
    "\n",
    "    \n",
    "    def cumulate_seq(self, seq: list):\n",
    "        # Calculates the cumulative time for a sequence of jobs on machines.\n",
    "\n",
    "        cumulated = None\n",
    "        for i in seq:\n",
    "            cumulated = self.cumulate(self.jobs_list[i], cumulated)\n",
    "        return cumulated\n",
    "\n",
    "    \n",
    "    def evaluate_makespan(self, schedule):\n",
    "        # Evaluates the makespan (completion time) of a given schedule.\n",
    "\n",
    "        cumulative = self.cumulate_seq(schedule)\n",
    "        return cumulative[-1]\n",
    "\n",
    "    \n",
    "    def initialize_population(self, init_type, population_size):\n",
    "        \"\"\"\n",
    "        Initializes the population of individuals.\n",
    "        \n",
    "        Args:\n",
    "            init_type (str): Type of initialization method.\n",
    "            population_size (int): Size of the population.\n",
    "            \n",
    "        Returns:\n",
    "            list: Initialized population of individuals.\n",
    "        \"\"\"\n",
    "        \n",
    "        def perturb_sequence(sequence):\n",
    "            \"\"\"\n",
    "            Perturbs a sequence by swapping two random jobs.\n",
    "            \n",
    "            Args:\n",
    "                sequence (list): Sequence of jobs.\n",
    "                \n",
    "            Returns:\n",
    "                list: Perturbed sequence.\n",
    "            \"\"\"\n",
    "            perturbed_seq = sequence[:]\n",
    "            for _ in range(2):\n",
    "                i, j = random.sample(range(len(perturbed_seq)), 2)\n",
    "                perturbed_seq[i], perturbed_seq[j] = perturbed_seq[j], perturbed_seq[i]\n",
    "            return perturbed_seq\n",
    "\n",
    "        population = []\n",
    "        \n",
    "        if init_type == \"cds\":\n",
    "            cds_seq, _ = heuristics.cds_heuristic(np.array(self.jobs_list))\n",
    "            population.append(cds_seq)\n",
    "            for _ in range(population_size - 1):\n",
    "                perturbed_seq = perturb_sequence(cds_seq)\n",
    "                population.append(perturbed_seq)\n",
    "\n",
    "        elif init_type == \"palmer\":\n",
    "            palmer_seq, _ = heuristics.Palmer(self.jobs_list).optim()\n",
    "            population.append(palmer_seq)\n",
    "            for _ in range(population_size - 1):\n",
    "                perturbed_seq = perturb_sequence(palmer_seq)\n",
    "                population.append(perturbed_seq)\n",
    "\n",
    "        elif init_type == \"neh\":\n",
    "            _, neh_seq = heuristics.NEH(self.tai_inst)()\n",
    "            population.append(neh_seq)\n",
    "            for _ in range(population_size - 1):\n",
    "                perturbed_seq = perturb_sequence(neh_seq)\n",
    "                population.append(perturbed_seq)\n",
    "\n",
    "        elif init_type == \"heuristics\":\n",
    "            cds_size = population_size // 3\n",
    "            palmer_size = population_size // 3\n",
    "            neh_size = population_size - cds_size - palmer_size\n",
    "            \n",
    "            for _ in range(cds_size):\n",
    "                cds_seq, _ = heuristics.cds_heuristic(np.array(self.jobs_list))\n",
    "                population.append(perturb_sequence(cds_seq))\n",
    "            \n",
    "            for _ in range(palmer_size):\n",
    "                palmer_seq, _ = heuristics.Palmer(self.jobs_list).optim()\n",
    "                population.append(perturb_sequence(palmer_seq))\n",
    "            \n",
    "            for _ in range(neh_size):\n",
    "                _, neh_seq = heuristics.NEH(self.tai_inst)()\n",
    "                population.append(perturb_sequence(neh_seq))\n",
    "\n",
    "        elif init_type == \"heuristics_random\":\n",
    "\n",
    "            cds_seq, _ = heuristics.cds_heuristic(np.array(self.jobs_list))\n",
    "            population.append(perturb_sequence(cds_seq))\n",
    "\n",
    "            palmer_seq, _ = heuristics.Palmer(self.jobs_list).optim()\n",
    "            population.append(perturb_sequence(palmer_seq))\n",
    "\n",
    "            _, neh_seq = heuristics.NEH(self.tai_inst)()\n",
    "            population.append(perturb_sequence(neh_seq))\n",
    "\n",
    "            for _ in range(population_size - 3):\n",
    "                random_seq = random.sample(range(self.nb_jobs), self.nb_jobs)\n",
    "                population.append(random_seq)\n",
    "\n",
    "        elif init_type == \"full_random\":\n",
    "\n",
    "            for _ in range(population_size):\n",
    "                random_seq = random.sample(range(self.nb_jobs), self.nb_jobs)\n",
    "                population.append(random_seq)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid initialization type\")\n",
    "\n",
    "        return population\n",
    "\n",
    "    \n",
    "    def select_parents(self, population):\n",
    "        \"\"\"\n",
    "        Selects parents from the population using tournament selection.\n",
    "        \n",
    "        Args:\n",
    "            population (list): Population of individuals.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Pair of selected parents.\n",
    "        \"\"\"\n",
    "        tournament = random.sample(population, 3)\n",
    "        tournament.sort(key=lambda x: self.evaluate_makespan(x))\n",
    "        return tournament[0], tournament[1]\n",
    "\n",
    "    \n",
    "    def crossover(self, crossover_type, parent1, parent2, crossover_rate, k_points=None):\n",
    "        \"\"\"\n",
    "        Performs crossover between two parents to produce offspring.\n",
    "        \n",
    "        Args:\n",
    "            crossover_type (str): Type of crossover operation.\n",
    "            parent1 (list): First parent.\n",
    "            parent2 (list): Second parent.\n",
    "            crossover_rate (float): Rate of crossover.\n",
    "            k (int, optional): Parameter for k-point crossover. Defaults to None.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Pair of offspring.\n",
    "        \"\"\"\n",
    "\n",
    "        def ensure_each_job_once(offspring):\n",
    "            \"\"\"\n",
    "            Ensures each job appears exactly once in the offspring.\n",
    "            \n",
    "            Args:\n",
    "                offspring (list): Offspring sequence.\n",
    "            \"\"\"\n",
    "            # Ensure offspring contains each job exactly once\n",
    "            job_count = {job: 0 for job in range(self.nb_jobs)}\n",
    "            for job in offspring:\n",
    "                job_count[job] += 1\n",
    "            for i, job in enumerate(offspring):\n",
    "                if job_count[job] > 1:\n",
    "                    for swap_job, count in job_count.items():\n",
    "                        if count == 0:\n",
    "                            offspring[i] = swap_job\n",
    "                            job_count[swap_job] += 1\n",
    "                            job_count[job] -= 1\n",
    "                            break\n",
    "\n",
    "        if random.random() < crossover_rate:\n",
    "            \n",
    "            if crossover_type == 'uniform':\n",
    "                k = None\n",
    "                mask = [random.choice([0, 1]) for _ in range(len(parent1))]\n",
    "                offspring1 = [gene1 if bit else gene2 for gene1, gene2, bit in zip(parent1, parent2, mask)]\n",
    "                offspring2 = [gene1 if bit else gene2 for gene1, gene2, bit in zip(parent2, parent1, mask)]\n",
    "\n",
    "            else:\n",
    "                if k_points is None or k_points < 1:\n",
    "                    raise ValueError(\"k must be >= 1 for one_point, two_points, and k_points crossovers\")\n",
    "                \n",
    "                if k_points is not None and k_points >= self.nb_jobs:\n",
    "                    raise ValueError(\"k in crossover must be less than the number of jobs\")\n",
    "\n",
    "                if ((crossover_type == 'one_point') or (k_points == 1)):\n",
    "                    k = 1\n",
    "                    points = [random.randint(1, len(parent1) - 1)]\n",
    "\n",
    "                elif ((crossover_type == 'two_points') or (k_points == 2)):\n",
    "                    k = 2\n",
    "                    points = sorted(random.sample(range(1, len(parent1)), 2))\n",
    "\n",
    "                elif crossover_type == 'k_points':\n",
    "                    points = sorted(random.sample(range(1, len(parent1)), k_points))\n",
    "\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid crossover type\")\n",
    "\n",
    "                offspring1, offspring2 = parent1[:], parent2[:]\n",
    "                switch = False\n",
    "                for i in range(len(parent1)):\n",
    "                    if i in points:\n",
    "                        switch = not switch\n",
    "                    if switch:\n",
    "                        offspring1[i], offspring2[i] = offspring2[i], offspring1[i]\n",
    "\n",
    "            ensure_each_job_once(offspring1)\n",
    "            ensure_each_job_once(offspring2)\n",
    "            return offspring1, offspring2\n",
    "        \n",
    "        else:\n",
    "            return parent1[:], parent2[:]\n",
    "\n",
    "\n",
    "    def mutate(self, solution, mutation_rate):\n",
    "        \"\"\"\n",
    "        Mutates a solution with a given mutation rate.\n",
    "        \n",
    "        Args:\n",
    "            solution (list): Solution to mutate.\n",
    "            mutation_rate (float): Rate of mutation.\n",
    "            \n",
    "        Returns:\n",
    "            list: Mutated solution.\n",
    "        \"\"\"\n",
    "        if random.random() < mutation_rate:\n",
    "            i, j = random.sample(range(len(solution)), 2)\n",
    "            solution[i], solution[j] = solution[j], solution[i]\n",
    "        return solution\n",
    "\n",
    "\n",
    "    def select_reproduction_pool(self, selection_type, population, pool_size):\n",
    "        \"\"\"\n",
    "        Selects a pool of individuals for reproduction.\n",
    "        \n",
    "        Args:\n",
    "            selection_type (str): Type of selection method.\n",
    "            population (list): Population of individuals.\n",
    "            pool_size (int): Size of the pool.\n",
    "            \n",
    "        Returns:\n",
    "            list: Pool of selected individuals.\n",
    "        \"\"\"\n",
    "        \n",
    "        chosen = []\n",
    "\n",
    "        if selection_type == \"roulette\":\n",
    "            total_fitness = sum(self.evaluate_makespan(ind) for ind in population)\n",
    "            selection_probs = [self.evaluate_makespan(ind) / total_fitness for ind in population]\n",
    "            chosen = random.choices(population, weights=selection_probs, k=pool_size)\n",
    "\n",
    "        elif selection_type == \"rank\":\n",
    "            population_sorted = sorted(population, key=self.evaluate_makespan)\n",
    "            ranks = range(1, len(population_sorted) + 1)\n",
    "            total_rank = sum(ranks)\n",
    "            rank_weights = [rank / total_rank for rank in ranks]\n",
    "            chosen = random.choices(population_sorted, weights=rank_weights, k=pool_size)\n",
    "\n",
    "        elif selection_type == \"elitist\":\n",
    "            population_sorted = sorted(population, key=self.evaluate_makespan)\n",
    "            chosen = population_sorted[:pool_size]\n",
    "\n",
    "        elif selection_type == \"tournament\":\n",
    "            for _ in range(pool_size):\n",
    "                contenders = random.sample(population, 3)\n",
    "                chosen.append(min(contenders, key=self.evaluate_makespan))\n",
    "\n",
    "        elif selection_type == \"random\":\n",
    "            chosen = random.sample(population, pool_size)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Invalid type\")\n",
    "\n",
    "        return chosen\n",
    "\n",
    "    \n",
    "    def replace_population(self, replacement_type, population, parents, offspring, population_size):\n",
    "        \"\"\"\n",
    "        Replaces the population with new individuals.\n",
    "        \n",
    "        Args:\n",
    "            replacement_type (str): Type of replacement method.\n",
    "            population (list): Current population.\n",
    "            parents (list): Parents generated during reproduction.\n",
    "            offspring (list): Offspring generated during reproduction.\n",
    "            population_size (int): Size of the population.\n",
    "            \n",
    "        Returns:\n",
    "            list: New population.\n",
    "        \"\"\"\n",
    "        \n",
    "        def select_population(selection_type, population, pool_size):\n",
    "            \"\"\"\n",
    "            Selects individuals for the next population.\n",
    "            \n",
    "            Args:\n",
    "                selection_type (str): Type of selection method.\n",
    "                population (list): Population of individuals.\n",
    "                pool_size (int): Size of the selection pool.\n",
    "                \n",
    "            Returns:\n",
    "                list: Selected individuals for the next population.\n",
    "            \"\"\"\n",
    "            return self.select_reproduction_pool(selection_type, population, pool_size)\n",
    "\n",
    "        if replacement_type == \"best_all\":\n",
    "            combined_population = population + offspring\n",
    "            combined_population.sort(key=lambda x: self.evaluate_makespan(x))\n",
    "            return combined_population[:population_size]\n",
    "\n",
    "        elif replacement_type == \"parents_replaced_by_offspring\":\n",
    "            population_without_parents = [ind for ind in population if ind not in parents]\n",
    "            return population_without_parents + offspring\n",
    "\n",
    "        elif replacement_type == \"worst_population_replaced_by_offspring\":\n",
    "            population_sorted = sorted(population, key=self.evaluate_makespan)\n",
    "            population_without_worst = population_sorted[:-len(offspring)]\n",
    "            return population_without_worst + offspring\n",
    "\n",
    "        elif replacement_type == \"best_between_parents_and_offspring\":\n",
    "            population_without_parents = [ind for ind in population if ind not in parents]\n",
    "            combined_sub_population = sorted(parents + offspring, key=self.evaluate_makespan)\n",
    "            return population_without_parents + combined_sub_population[:len(parents)]\n",
    "        \n",
    "        else:\n",
    "            return select_population(replacement_type, population + offspring, len(population))\n",
    "    \n",
    "\n",
    "    def genetic_algorithm(self, init_type, selection_type, crossover_type, replacement_type, population_size, pool_size, crossover_rate, mutation_rate, num_iterations, max_stagnation, k_points=None):\n",
    "        \"\"\"\n",
    "        Executes the Genetic Algorithm to find the best solution.\n",
    "        \n",
    "        Args:\n",
    "            init_type (str): Type of initialization method.\n",
    "            selection_type (str): Type of parent selection method.\n",
    "            crossover_type (str): Type of crossover method.\n",
    "            replacement_type (str): Type of population replacement method.\n",
    "            population_size (int): Size of the population.\n",
    "            pool_size (int): Size of the reproduction pool.\n",
    "            crossover_rate (float): Rate of crossover.\n",
    "            mutation_rate (float): Rate of mutation.\n",
    "            num_iterations (int): Maximum number of iterations.\n",
    "            max_stagnation (int): Maximum number of iterations without improvement.\n",
    "            k_points (int, optional): Parameter for k-point crossover. Defaults to None.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Best solution and its makespan.\n",
    "        \"\"\"\n",
    "        \n",
    "        if pool_size > population_size:\n",
    "            raise ValueError(\"Pool size must be less than population size.\")\n",
    "\n",
    "        population = self.initialize_population(init_type, population_size)\n",
    "        population.sort(key=lambda x: self.evaluate_makespan(x))\n",
    "        \n",
    "        best_solution = population[0]\n",
    "        best_solution_fitness = self.evaluate_makespan(best_solution)\n",
    "        stagnation_count = 0\n",
    "\n",
    "        for i in range(num_iterations):\n",
    "            reproduction_pool = self.select_reproduction_pool(selection_type, population, pool_size)\n",
    "            offspring = []\n",
    "            parents = []\n",
    "\n",
    "            for _ in range(pool_size // 2):\n",
    "                parent1, parent2 = self.select_parents(reproduction_pool)\n",
    "                parents.extend([parent1, parent2])\n",
    "                child1, child2 = self.crossover(crossover_type, parent1, parent2, crossover_rate, k_points) \n",
    "                child1 = self.mutate(child1, mutation_rate)\n",
    "                child2 = self.mutate(child2, mutation_rate)\n",
    "                offspring.extend([child1, child2])\n",
    "\n",
    "            population = self.replace_population(replacement_type, population, parents, offspring, population_size)\n",
    "            population.sort(key=lambda x: self.evaluate_makespan(x))\n",
    "\n",
    "            current_best_solution = population[0]\n",
    "            current_best_solution_fitness = self.evaluate_makespan(current_best_solution)\n",
    "\n",
    "            if current_best_solution_fitness < best_solution_fitness:\n",
    "                best_solution = current_best_solution\n",
    "                best_solution_fitness = current_best_solution_fitness\n",
    "                stagnation_count = 0\n",
    "            else:\n",
    "                stagnation_count += 1\n",
    "\n",
    "            if max_stagnation is not None and stagnation_count >= max_stagnation:\n",
    "                break\n",
    "\n",
    "        return best_solution\n",
    "\n",
    "    \n",
    "    def fit(self, \n",
    "            init_type = 'heuristics', \n",
    "            selection_type = 'random', \n",
    "            crossover_type = 'one_point', \n",
    "            replacement_type = 'best_all', \n",
    "            population_size = 20, \n",
    "            pool_size = 15, \n",
    "            crossover_rate = 0.8, \n",
    "            mutation_rate = 0.1, \n",
    "            num_iterations = 200,\n",
    "            max_stagnation = 10,\n",
    "            k_points = 1\n",
    "            ):\n",
    "        \n",
    "        self.seq_star = self.genetic_algorithm(init_type, selection_type, crossover_type, replacement_type, population_size, pool_size, crossover_rate, mutation_rate, num_iterations, max_stagnation, k_points)\n",
    "        self.make_span_star = self.evaluate_makespan(self.seq_star)\n",
    "        return self.make_span_star, self.seq_star\n",
    "    \n",
    "\n",
    "def exec_ga(instances, n_trials=10):\n",
    "    studies = []\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    for i, instance in enumerate(instances):\n",
    "        study = optuna.create_study()\n",
    "        ga = GeneticAlgorithm(instance)\n",
    "        def objective(trial):\n",
    "            init_type = trial.suggest_categorical(\"init_type\", ['cds', 'palmer', 'neh', 'heuristics', 'heuristics_random', 'full_random'])\n",
    "            selection_type = trial.suggest_categorical(\"selection_type\", ['roulette', 'rank', 'elitist', 'tournament', 'random'])\n",
    "            crossover_type = trial.suggest_categorical(\"crossover_type\", ['uniform', 'one_point', 'two_points', 'k_points'])\n",
    "            replacement_type = trial.suggest_categorical(\"replacement_type\", ['best_all', 'parents_replaced_by_offspring', 'worst_population_replaced_by_offspring', 'best_between_parents_and_offspring', 'roulette', 'rank', 'elitist', 'tournament', 'random'])     \n",
    "            population_size = trial.suggest_int(\"population_size\", 20, 50, step=10)\n",
    "            pool_size = trial.suggest_int(\"pool_size\", 10, 20, step=5)\n",
    "            crossover_rate = trial.suggest_float(\"crossover_rate\", 0.1, 0.9, step=0.1)\n",
    "            mutation_rate = trial.suggest_float(\"mutation_rate\", 0.1, 0.9, step=0.1)\n",
    "            num_iterations = trial.suggest_int(\"num_iterations\", 200, 1000, step=100)\n",
    "            max_stagnation = trial.suggest_int(\"max_stagnation\", 50, 200, step=50)\n",
    "            k_points = trial.suggest_int(\"k_points\", 1, 3, step=1)\n",
    "\n",
    "            return ga.fit(init_type, selection_type, crossover_type, replacement_type, population_size, pool_size, crossover_rate, mutation_rate, num_iterations, max_stagnation, k_points)[0]\n",
    "\n",
    "        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "        studies.append(copy.deepcopy(study))\n",
    "    \n",
    "    return studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "css = [\n",
    "        {'selector': '', 'props': [('min-width', '110px')]},\n",
    "        {'selector': 'th', 'props': [('min-width', '110px')]}\n",
    "      ]\n",
    "\n",
    "def compare(instances, study_lsaga, study_ga, study_sa, cds, palmer, neh):\n",
    "\n",
    "    def highlight(s):\n",
    "        is_min = s == s.min()\n",
    "        is_max = s == s.max()\n",
    "        return ['color: green; font-weight: bold' if v else 'color: red; font-weight: bold' if w else '' for v, w in zip(is_min, is_max)]\n",
    "\n",
    "\n",
    "    # Define the data\n",
    "    instance_names = [f\"Instance {i+1}\" for i in range(len(instances))]\n",
    "\n",
    "    data = {\n",
    "                'LSAGA' : study_lsaga,\n",
    "                'Genetic Algorithm' : [int(study.best_value) for study in study_ga],\n",
    "                'Simmulated annealing' : [int(study.best_value) for study in study_sa],\n",
    "                'CDS': cds,\n",
    "                'Palmer': palmer,\n",
    "                'NEH': neh,\n",
    "                'Upper bound': [instance.ub for instance in instances]\n",
    "           }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.index = instance_names\n",
    "    styled_df = df.style.apply(highlight, axis=1, subset=df.columns[:-1])\n",
    "    return styled_df.set_table_styles(css)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 jobs 5 machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Temperature 0.00515377520732012:  10%|█         | 50/500 [02:15<20:18,  2.71s/it] \n",
      "Temperature 0.011972515182562033:   8%|▊         | 42/500 [01:13<13:20,  1.75s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m instance \u001b[38;5;129;01min\u001b[39;00m instances_20_5:\n\u001b[0;32m      4\u001b[0m     saga \u001b[38;5;241m=\u001b[39m LSAGA(instance, variety_degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     \u001b[43msaga\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.005\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     makes_spans_20_5\u001b[38;5;241m.\u001b[39mappend(saga\u001b[38;5;241m.\u001b[39mmake_span_star)\n",
      "Cell \u001b[1;32mIn[14], line 586\u001b[0m, in \u001b[0;36mLSAGA.optim\u001b[1;34m(self, T, T_min, alpha, nb_iter, init_method, neigh_method, length_palier, jump_rate, jump_ratio, debug, trace)\u001b[0m\n\u001b[0;32m    584\u001b[0m new_hps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_neigh_hps(hps, T)\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m#compute the energy difference\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m neigh_seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenetic_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_hps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    587\u001b[0m neigh_make_span \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_makespan(neigh_seq)\n\u001b[0;32m    588\u001b[0m delta \u001b[38;5;241m=\u001b[39m current_make_span \u001b[38;5;241m-\u001b[39m neigh_make_span\n",
      "Cell \u001b[1;32mIn[14], line 434\u001b[0m, in \u001b[0;36mLSAGA.genetic_algorithm\u001b[1;34m(self, init_type, selection_type, crossover_type, replacement_type, population_size, pool_size, crossover_rate, mutation_rate, num_iterations, max_stagnation, k_points)\u001b[0m\n\u001b[0;32m    431\u001b[0m     offspring\u001b[38;5;241m.\u001b[39mextend([child1, child2])\n\u001b[0;32m    433\u001b[0m population \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplace_population(replacement_type, population, parents, offspring, population_size)\n\u001b[1;32m--> 434\u001b[0m \u001b[43mpopulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_makespan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m current_best_solution \u001b[38;5;241m=\u001b[39m population[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    437\u001b[0m current_best_solution_fitness \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_makespan(current_best_solution)\n",
      "Cell \u001b[1;32mIn[14], line 434\u001b[0m, in \u001b[0;36mLSAGA.genetic_algorithm.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    431\u001b[0m     offspring\u001b[38;5;241m.\u001b[39mextend([child1, child2])\n\u001b[0;32m    433\u001b[0m population \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplace_population(replacement_type, population, parents, offspring, population_size)\n\u001b[1;32m--> 434\u001b[0m population\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_makespan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    436\u001b[0m current_best_solution \u001b[38;5;241m=\u001b[39m population[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    437\u001b[0m current_best_solution_fitness \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_makespan(current_best_solution)\n",
      "Cell \u001b[1;32mIn[14], line 88\u001b[0m, in \u001b[0;36mLSAGA.evaluate_makespan\u001b[1;34m(self, schedule)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_makespan\u001b[39m(\u001b[38;5;28mself\u001b[39m, schedule):\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m# Evaluates the makespan (completion time) of a given schedule.\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     cumulative \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumulate_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschedule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cumulative[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[14], line 82\u001b[0m, in \u001b[0;36mLSAGA.cumulate_seq\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m     80\u001b[0m cumulated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m seq:\n\u001b[1;32m---> 82\u001b[0m     cumulated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumulate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcumulated\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cumulated\n",
      "Cell \u001b[1;32mIn[14], line 63\u001b[0m, in \u001b[0;36mLSAGA.cumulate\u001b[1;34m(self, job, previous_cumul)\u001b[0m\n\u001b[0;32m     60\u001b[0m             jobs_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(tai_inst\u001b[38;5;241m.\u001b[39mmatrix[j][i])\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jobs_list\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcumulate\u001b[39m(\u001b[38;5;28mself\u001b[39m, job: \u001b[38;5;28mlist\u001b[39m, previous_cumul\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Calculate the cumulative completion times for a job\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     res \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(job)\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_cumul \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "instances_20_5 = load_tai(20,5)\n",
    "makes_spans_20_5 = []\n",
    "for instance in instances_20_5:\n",
    "    saga = LSAGA(instance, variety_degree=4)\n",
    "    saga.optim(T_min=0.005)\n",
    "    makes_spans_20_5.append(saga.make_span_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing heursitics\n",
      "tuning simulated annealing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1297: 100%|██████████| 10/10 [00:00<00:00, 46.25it/s]\n",
      "Best trial: 6. Best value: 1368: 100%|██████████| 10/10 [00:00<00:00, 38.10it/s]\n",
      "Best trial: 1. Best value: 1098: 100%|██████████| 10/10 [00:00<00:00, 26.78it/s]\n",
      "Best trial: 1. Best value: 1307: 100%|██████████| 10/10 [00:00<00:00, 51.73it/s]\n",
      "Best trial: 4. Best value: 1250: 100%|██████████| 10/10 [00:00<00:00, 50.89it/s]\n",
      "Best trial: 9. Best value: 1210: 100%|██████████| 10/10 [00:00<00:00, 41.36it/s]\n",
      "Best trial: 6. Best value: 1251: 100%|██████████| 10/10 [00:00<00:00, 47.29it/s]\n",
      "Best trial: 7. Best value: 1211: 100%|██████████| 10/10 [00:00<00:00, 40.26it/s]\n",
      "Best trial: 1. Best value: 1254: 100%|██████████| 10/10 [00:00<00:00, 30.02it/s]\n",
      "Best trial: 3. Best value: 1130: 100%|██████████| 10/10 [00:00<00:00, 37.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning genetic algorithm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 1297: 100%|██████████| 10/10 [00:12<00:00,  1.28s/it]\n",
      "Best trial: 6. Best value: 1366: 100%|██████████| 10/10 [00:07<00:00,  1.28it/s]\n",
      "Best trial: 2. Best value: 1098: 100%|██████████| 10/10 [00:15<00:00,  1.55s/it]\n",
      "Best trial: 5. Best value: 1302: 100%|██████████| 10/10 [00:46<00:00,  4.67s/it]\n",
      "Best trial: 1. Best value: 1250: 100%|██████████| 10/10 [00:07<00:00,  1.41it/s]\n",
      "Best trial: 2. Best value: 1224: 100%|██████████| 10/10 [00:07<00:00,  1.43it/s]\n",
      "Best trial: 7. Best value: 1251: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Best trial: 4. Best value: 1218: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Best trial: 5. Best value: 1255: 100%|██████████| 10/10 [00:05<00:00,  1.85it/s]\n",
      "Best trial: 4. Best value: 1120: 100%|██████████| 10/10 [00:08<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"executing heursitics\")\n",
    "cds, palmer, neh = exec_heur(instances_20_5)\n",
    "print(\"optuna tuning simulated annealing\")\n",
    "study_sa = exec_sa(instances_20_5)\n",
    "print(\"optuna tuning genetic algorithm\")\n",
    "study_ga = exec_ga(instances_20_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_678f5  {\n",
       "  min-width: 110px;\n",
       "}\n",
       "#T_678f5 th {\n",
       "  min-width: 110px;\n",
       "}\n",
       "#T_678f5_row0_col0, #T_678f5_row1_col0, #T_678f5_row2_col0, #T_678f5_row3_col1, #T_678f5_row4_col0, #T_678f5_row4_col1, #T_678f5_row4_col2, #T_678f5_row5_col0, #T_678f5_row5_col2, #T_678f5_row6_col0, #T_678f5_row6_col1, #T_678f5_row6_col2, #T_678f5_row7_col0, #T_678f5_row7_col2, #T_678f5_row8_col0, #T_678f5_row9_col0 {\n",
       "  color: green;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_678f5_row0_col3, #T_678f5_row1_col4, #T_678f5_row2_col3, #T_678f5_row3_col4, #T_678f5_row4_col4, #T_678f5_row5_col4, #T_678f5_row6_col4, #T_678f5_row7_col3, #T_678f5_row8_col4, #T_678f5_row9_col4 {\n",
       "  color: red;\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_678f5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_678f5_level0_col0\" class=\"col_heading level0 col0\" >LSAGA</th>\n",
       "      <th id=\"T_678f5_level0_col1\" class=\"col_heading level0 col1\" >Genetic Algorithm</th>\n",
       "      <th id=\"T_678f5_level0_col2\" class=\"col_heading level0 col2\" >Simmulated annealing</th>\n",
       "      <th id=\"T_678f5_level0_col3\" class=\"col_heading level0 col3\" >CDS</th>\n",
       "      <th id=\"T_678f5_level0_col4\" class=\"col_heading level0 col4\" >Palmer</th>\n",
       "      <th id=\"T_678f5_level0_col5\" class=\"col_heading level0 col5\" >NEH</th>\n",
       "      <th id=\"T_678f5_level0_col6\" class=\"col_heading level0 col6\" >Upper bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_678f5_level0_row0\" class=\"row_heading level0 row0\" >Instance 1</th>\n",
       "      <td id=\"T_678f5_row0_col0\" class=\"data row0 col0\" >1279</td>\n",
       "      <td id=\"T_678f5_row0_col1\" class=\"data row0 col1\" >1297</td>\n",
       "      <td id=\"T_678f5_row0_col2\" class=\"data row0 col2\" >1297</td>\n",
       "      <td id=\"T_678f5_row0_col3\" class=\"data row0 col3\" >1422</td>\n",
       "      <td id=\"T_678f5_row0_col4\" class=\"data row0 col4\" >1384</td>\n",
       "      <td id=\"T_678f5_row0_col5\" class=\"data row0 col5\" >1334</td>\n",
       "      <td id=\"T_678f5_row0_col6\" class=\"data row0 col6\" >1278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_678f5_level0_row1\" class=\"row_heading level0 row1\" >Instance 2</th>\n",
       "      <td id=\"T_678f5_row1_col0\" class=\"data row1 col0\" >1360</td>\n",
       "      <td id=\"T_678f5_row1_col1\" class=\"data row1 col1\" >1366</td>\n",
       "      <td id=\"T_678f5_row1_col2\" class=\"data row1 col2\" >1368</td>\n",
       "      <td id=\"T_678f5_row1_col3\" class=\"data row1 col3\" >1424</td>\n",
       "      <td id=\"T_678f5_row1_col4\" class=\"data row1 col4\" >1439</td>\n",
       "      <td id=\"T_678f5_row1_col5\" class=\"data row1 col5\" >1377</td>\n",
       "      <td id=\"T_678f5_row1_col6\" class=\"data row1 col6\" >1359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_678f5_level0_row2\" class=\"row_heading level0 row2\" >Instance 3</th>\n",
       "      <td id=\"T_678f5_row2_col0\" class=\"data row2 col0\" >1096</td>\n",
       "      <td id=\"T_678f5_row2_col1\" class=\"data row2 col1\" >1098</td>\n",
       "      <td id=\"T_678f5_row2_col2\" class=\"data row2 col2\" >1098</td>\n",
       "      <td id=\"T_678f5_row2_col3\" class=\"data row2 col3\" >1255</td>\n",
       "      <td id=\"T_678f5_row2_col4\" class=\"data row2 col4\" >1162</td>\n",
       "      <td id=\"T_678f5_row2_col5\" class=\"data row2 col5\" >1157</td>\n",
       "      <td id=\"T_678f5_row2_col6\" class=\"data row2 col6\" >1081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_678f5_level0_row3\" class=\"row_heading level0 row3\" >Instance 4</th>\n",
       "      <td id=\"T_678f5_row3_col0\" class=\"data row3 col0\" >1304</td>\n",
       "      <td id=\"T_678f5_row3_col1\" class=\"data row3 col1\" >1302</td>\n",
       "      <td id=\"T_678f5_row3_col2\" class=\"data row3 col2\" >1307</td>\n",
       "      <td id=\"T_678f5_row3_col3\" class=\"data row3 col3\" >1418</td>\n",
       "      <td id=\"T_678f5_row3_col4\" class=\"data row3 col4\" >1420</td>\n",
       "      <td id=\"T_678f5_row3_col5\" class=\"data row3 col5\" >1402</td>\n",
       "      <td id=\"T_678f5_row3_col6\" class=\"data row3 col6\" >1293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_678f5_level0_row4\" class=\"row_heading level0 row4\" >Instance 5</th>\n",
       "      <td id=\"T_678f5_row4_col0\" class=\"data row4 col0\" >1250</td>\n",
       "      <td id=\"T_678f5_row4_col1\" class=\"data row4 col1\" >1250</td>\n",
       "      <td id=\"T_678f5_row4_col2\" class=\"data row4 col2\" >1250</td>\n",
       "      <td id=\"T_678f5_row4_col3\" class=\"data row4 col3\" >1323</td>\n",
       "      <td id=\"T_678f5_row4_col4\" class=\"data row4 col4\" >1360</td>\n",
       "      <td id=\"T_678f5_row4_col5\" class=\"data row4 col5\" >1319</td>\n",
       "      <td id=\"T_678f5_row4_col6\" class=\"data row4 col6\" >1236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_678f5_level0_row5\" class=\"row_heading level0 row5\" >Instance 6</th>\n",
       "      <td id=\"T_678f5_row5_col0\" class=\"data row5 col0\" >1210</td>\n",
       "      <td id=\"T_678f5_row5_col1\" class=\"data row5 col1\" >1224</td>\n",
       "      <td id=\"T_678f5_row5_col2\" class=\"data row5 col2\" >1210</td>\n",
       "      <td id=\"T_678f5_row5_col3\" class=\"data row5 col3\" >1312</td>\n",
       "      <td id=\"T_678f5_row5_col4\" class=\"data row5 col4\" >1344</td>\n",
       "      <td id=\"T_678f5_row5_col5\" class=\"data row5 col5\" >1342</td>\n",
       "      <td id=\"T_678f5_row5_col6\" class=\"data row5 col6\" >1195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_678f5_level0_row6\" class=\"row_heading level0 row6\" >Instance 7</th>\n",
       "      <td id=\"T_678f5_row6_col0\" class=\"data row6 col0\" >1251</td>\n",
       "      <td id=\"T_678f5_row6_col1\" class=\"data row6 col1\" >1251</td>\n",
       "      <td id=\"T_678f5_row6_col2\" class=\"data row6 col2\" >1251</td>\n",
       "      <td id=\"T_678f5_row6_col3\" class=\"data row6 col3\" >1393</td>\n",
       "      <td id=\"T_678f5_row6_col4\" class=\"data row6 col4\" >1400</td>\n",
       "      <td id=\"T_678f5_row6_col5\" class=\"data row6 col5\" >1268</td>\n",
       "      <td id=\"T_678f5_row6_col6\" class=\"data row6 col6\" >1239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_678f5_level0_row7\" class=\"row_heading level0 row7\" >Instance 8</th>\n",
       "      <td id=\"T_678f5_row7_col0\" class=\"data row7 col0\" >1211</td>\n",
       "      <td id=\"T_678f5_row7_col1\" class=\"data row7 col1\" >1218</td>\n",
       "      <td id=\"T_678f5_row7_col2\" class=\"data row7 col2\" >1211</td>\n",
       "      <td id=\"T_678f5_row7_col3\" class=\"data row7 col3\" >1345</td>\n",
       "      <td id=\"T_678f5_row7_col4\" class=\"data row7 col4\" >1290</td>\n",
       "      <td id=\"T_678f5_row7_col5\" class=\"data row7 col5\" >1262</td>\n",
       "      <td id=\"T_678f5_row7_col6\" class=\"data row7 col6\" >1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_678f5_level0_row8\" class=\"row_heading level0 row8\" >Instance 9</th>\n",
       "      <td id=\"T_678f5_row8_col0\" class=\"data row8 col0\" >1253</td>\n",
       "      <td id=\"T_678f5_row8_col1\" class=\"data row8 col1\" >1255</td>\n",
       "      <td id=\"T_678f5_row8_col2\" class=\"data row8 col2\" >1254</td>\n",
       "      <td id=\"T_678f5_row8_col3\" class=\"data row8 col3\" >1360</td>\n",
       "      <td id=\"T_678f5_row8_col4\" class=\"data row8 col4\" >1426</td>\n",
       "      <td id=\"T_678f5_row8_col5\" class=\"data row8 col5\" >1346</td>\n",
       "      <td id=\"T_678f5_row8_col6\" class=\"data row8 col6\" >1230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_678f5_level0_row9\" class=\"row_heading level0 row9\" >Instance 10</th>\n",
       "      <td id=\"T_678f5_row9_col0\" class=\"data row9 col0\" >1114</td>\n",
       "      <td id=\"T_678f5_row9_col1\" class=\"data row9 col1\" >1120</td>\n",
       "      <td id=\"T_678f5_row9_col2\" class=\"data row9 col2\" >1130</td>\n",
       "      <td id=\"T_678f5_row9_col3\" class=\"data row9 col3\" >1164</td>\n",
       "      <td id=\"T_678f5_row9_col4\" class=\"data row9 col4\" >1229</td>\n",
       "      <td id=\"T_678f5_row9_col5\" class=\"data row9 col5\" >1227</td>\n",
       "      <td id=\"T_678f5_row9_col6\" class=\"data row9 col6\" >1108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x299ec44abd0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(instances_20_5, makes_spans_20_5, study_ga, study_sa, cds, palmer, neh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 jobs 10 machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [02:39<28:20,  3.72s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [02:23<25:28,  3.35s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [01:29<15:54,  2.09s/it]  \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [01:26<15:14,  2.00s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [01:00<10:42,  1.41s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [02:08<22:41,  2.98s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [01:38<17:28,  2.29s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [01:33<16:28,  2.16s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [03:06<32:58,  4.33s/it]   \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [02:36<27:40,  3.63s/it]  \n"
     ]
    }
   ],
   "source": [
    "instances_20_10 = load_tai(20,10)\n",
    "makes_spans_20_10 = []\n",
    "for instance in instances_20_10:\n",
    "    saga = LSAGA(instance, variety_degree=3)\n",
    "    saga.optim(T_min=0.01)\n",
    "    makes_spans_20_10.append(saga.make_span_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing heursitics\n",
      "tuning simulated annealing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1637: 100%|██████████| 10/10 [00:00<00:00, 34.33it/s]\n",
      "Best trial: 3. Best value: 1717: 100%|██████████| 10/10 [00:00<00:00, 43.19it/s]\n",
      "Best trial: 0. Best value: 1554: 100%|██████████| 10/10 [00:00<00:00, 22.60it/s]\n",
      "Best trial: 9. Best value: 1443: 100%|██████████| 10/10 [00:00<00:00, 27.17it/s]\n",
      "Best trial: 2. Best value: 1471: 100%|██████████| 10/10 [00:00<00:00, 32.40it/s]\n",
      "Best trial: 9. Best value: 1434: 100%|██████████| 10/10 [00:00<00:00, 17.33it/s]\n",
      "Best trial: 7. Best value: 1525: 100%|██████████| 10/10 [00:00<00:00, 30.41it/s]\n",
      "Best trial: 7. Best value: 1606: 100%|██████████| 10/10 [00:00<00:00, 28.09it/s]\n",
      "Best trial: 9. Best value: 1659: 100%|██████████| 10/10 [00:00<00:00, 47.94it/s]\n",
      "Best trial: 1. Best value: 1652: 100%|██████████| 10/10 [00:00<00:00, 34.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning genetic algorithm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1600: 100%|██████████| 10/10 [00:52<00:00,  5.28s/it]\n",
      "Best trial: 9. Best value: 1703: 100%|██████████| 10/10 [00:15<00:00,  1.55s/it]\n",
      "Best trial: 0. Best value: 1548: 100%|██████████| 10/10 [00:11<00:00,  1.11s/it]\n",
      "Best trial: 2. Best value: 1422: 100%|██████████| 10/10 [00:23<00:00,  2.36s/it]\n",
      "Best trial: 6. Best value: 1475: 100%|██████████| 10/10 [00:17<00:00,  1.78s/it]\n",
      "Best trial: 9. Best value: 1433: 100%|██████████| 10/10 [01:01<00:00,  6.11s/it]\n",
      "Best trial: 0. Best value: 1493: 100%|██████████| 10/10 [00:15<00:00,  1.56s/it]\n",
      "Best trial: 1. Best value: 1588: 100%|██████████| 10/10 [00:24<00:00,  2.40s/it]\n",
      "Best trial: 8. Best value: 1611: 100%|██████████| 10/10 [00:11<00:00,  1.17s/it]\n",
      "Best trial: 4. Best value: 1631: 100%|██████████| 10/10 [00:24<00:00,  2.44s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"executing heursitics\")\n",
    "cds, palmer, neh = exec_heur(instances_20_10)\n",
    "print(\"tuning simulated annealing\")\n",
    "study_sa = exec_sa(instances_20_10)\n",
    "print(\"tuning genetic algorithm\")\n",
    "study_ga = exec_ga(instances_20_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f3a9b  {\n",
       "  min-width: 110px;\n",
       "}\n",
       "#T_f3a9b th {\n",
       "  min-width: 110px;\n",
       "}\n",
       "#T_f3a9b_row0_col1, #T_f3a9b_row1_col1, #T_f3a9b_row2_col0, #T_f3a9b_row3_col0, #T_f3a9b_row4_col0, #T_f3a9b_row5_col0, #T_f3a9b_row6_col1, #T_f3a9b_row7_col0, #T_f3a9b_row8_col1, #T_f3a9b_row9_col0, #T_f3a9b_row9_col1 {\n",
       "  color: green;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_f3a9b_row0_col4, #T_f3a9b_row1_col4, #T_f3a9b_row2_col4, #T_f3a9b_row3_col4, #T_f3a9b_row4_col4, #T_f3a9b_row5_col3, #T_f3a9b_row6_col4, #T_f3a9b_row7_col3, #T_f3a9b_row8_col4, #T_f3a9b_row9_col4 {\n",
       "  color: red;\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f3a9b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f3a9b_level0_col0\" class=\"col_heading level0 col0\" >LSAGA</th>\n",
       "      <th id=\"T_f3a9b_level0_col1\" class=\"col_heading level0 col1\" >Genetic Algorithm</th>\n",
       "      <th id=\"T_f3a9b_level0_col2\" class=\"col_heading level0 col2\" >Simmulated annealing</th>\n",
       "      <th id=\"T_f3a9b_level0_col3\" class=\"col_heading level0 col3\" >CDS</th>\n",
       "      <th id=\"T_f3a9b_level0_col4\" class=\"col_heading level0 col4\" >Palmer</th>\n",
       "      <th id=\"T_f3a9b_level0_col5\" class=\"col_heading level0 col5\" >NEH</th>\n",
       "      <th id=\"T_f3a9b_level0_col6\" class=\"col_heading level0 col6\" >Upper bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f3a9b_level0_row0\" class=\"row_heading level0 row0\" >Instance 1</th>\n",
       "      <td id=\"T_f3a9b_row0_col0\" class=\"data row0 col0\" >1621</td>\n",
       "      <td id=\"T_f3a9b_row0_col1\" class=\"data row0 col1\" >1600</td>\n",
       "      <td id=\"T_f3a9b_row0_col2\" class=\"data row0 col2\" >1637</td>\n",
       "      <td id=\"T_f3a9b_row0_col3\" class=\"data row0 col3\" >1757</td>\n",
       "      <td id=\"T_f3a9b_row0_col4\" class=\"data row0 col4\" >1790</td>\n",
       "      <td id=\"T_f3a9b_row0_col5\" class=\"data row0 col5\" >1675</td>\n",
       "      <td id=\"T_f3a9b_row0_col6\" class=\"data row0 col6\" >1582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f3a9b_level0_row1\" class=\"row_heading level0 row1\" >Instance 2</th>\n",
       "      <td id=\"T_f3a9b_row1_col0\" class=\"data row1 col0\" >1707</td>\n",
       "      <td id=\"T_f3a9b_row1_col1\" class=\"data row1 col1\" >1703</td>\n",
       "      <td id=\"T_f3a9b_row1_col2\" class=\"data row1 col2\" >1717</td>\n",
       "      <td id=\"T_f3a9b_row1_col3\" class=\"data row1 col3\" >1854</td>\n",
       "      <td id=\"T_f3a9b_row1_col4\" class=\"data row1 col4\" >1948</td>\n",
       "      <td id=\"T_f3a9b_row1_col5\" class=\"data row1 col5\" >1797</td>\n",
       "      <td id=\"T_f3a9b_row1_col6\" class=\"data row1 col6\" >1659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f3a9b_level0_row2\" class=\"row_heading level0 row2\" >Instance 3</th>\n",
       "      <td id=\"T_f3a9b_row2_col0\" class=\"data row2 col0\" >1540</td>\n",
       "      <td id=\"T_f3a9b_row2_col1\" class=\"data row2 col1\" >1548</td>\n",
       "      <td id=\"T_f3a9b_row2_col2\" class=\"data row2 col2\" >1554</td>\n",
       "      <td id=\"T_f3a9b_row2_col3\" class=\"data row2 col3\" >1661</td>\n",
       "      <td id=\"T_f3a9b_row2_col4\" class=\"data row2 col4\" >1729</td>\n",
       "      <td id=\"T_f3a9b_row2_col5\" class=\"data row2 col5\" >1567</td>\n",
       "      <td id=\"T_f3a9b_row2_col6\" class=\"data row2 col6\" >1496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f3a9b_level0_row3\" class=\"row_heading level0 row3\" >Instance 4</th>\n",
       "      <td id=\"T_f3a9b_row3_col0\" class=\"data row3 col0\" >1397</td>\n",
       "      <td id=\"T_f3a9b_row3_col1\" class=\"data row3 col1\" >1422</td>\n",
       "      <td id=\"T_f3a9b_row3_col2\" class=\"data row3 col2\" >1443</td>\n",
       "      <td id=\"T_f3a9b_row3_col3\" class=\"data row3 col3\" >1547</td>\n",
       "      <td id=\"T_f3a9b_row3_col4\" class=\"data row3 col4\" >1585</td>\n",
       "      <td id=\"T_f3a9b_row3_col5\" class=\"data row3 col5\" >1551</td>\n",
       "      <td id=\"T_f3a9b_row3_col6\" class=\"data row3 col6\" >1378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f3a9b_level0_row4\" class=\"row_heading level0 row4\" >Instance 5</th>\n",
       "      <td id=\"T_f3a9b_row4_col0\" class=\"data row4 col0\" >1444</td>\n",
       "      <td id=\"T_f3a9b_row4_col1\" class=\"data row4 col1\" >1475</td>\n",
       "      <td id=\"T_f3a9b_row4_col2\" class=\"data row4 col2\" >1471</td>\n",
       "      <td id=\"T_f3a9b_row4_col3\" class=\"data row4 col3\" >1558</td>\n",
       "      <td id=\"T_f3a9b_row4_col4\" class=\"data row4 col4\" >1648</td>\n",
       "      <td id=\"T_f3a9b_row4_col5\" class=\"data row4 col5\" >1479</td>\n",
       "      <td id=\"T_f3a9b_row4_col6\" class=\"data row4 col6\" >1419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f3a9b_level0_row5\" class=\"row_heading level0 row5\" >Instance 6</th>\n",
       "      <td id=\"T_f3a9b_row5_col0\" class=\"data row5 col0\" >1427</td>\n",
       "      <td id=\"T_f3a9b_row5_col1\" class=\"data row5 col1\" >1433</td>\n",
       "      <td id=\"T_f3a9b_row5_col2\" class=\"data row5 col2\" >1434</td>\n",
       "      <td id=\"T_f3a9b_row5_col3\" class=\"data row5 col3\" >1591</td>\n",
       "      <td id=\"T_f3a9b_row5_col4\" class=\"data row5 col4\" >1527</td>\n",
       "      <td id=\"T_f3a9b_row5_col5\" class=\"data row5 col5\" >1509</td>\n",
       "      <td id=\"T_f3a9b_row5_col6\" class=\"data row5 col6\" >1397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f3a9b_level0_row6\" class=\"row_heading level0 row6\" >Instance 7</th>\n",
       "      <td id=\"T_f3a9b_row6_col0\" class=\"data row6 col0\" >1503</td>\n",
       "      <td id=\"T_f3a9b_row6_col1\" class=\"data row6 col1\" >1493</td>\n",
       "      <td id=\"T_f3a9b_row6_col2\" class=\"data row6 col2\" >1525</td>\n",
       "      <td id=\"T_f3a9b_row6_col3\" class=\"data row6 col3\" >1630</td>\n",
       "      <td id=\"T_f3a9b_row6_col4\" class=\"data row6 col4\" >1735</td>\n",
       "      <td id=\"T_f3a9b_row6_col5\" class=\"data row6 col5\" >1593</td>\n",
       "      <td id=\"T_f3a9b_row6_col6\" class=\"data row6 col6\" >1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f3a9b_level0_row7\" class=\"row_heading level0 row7\" >Instance 8</th>\n",
       "      <td id=\"T_f3a9b_row7_col0\" class=\"data row7 col0\" >1571</td>\n",
       "      <td id=\"T_f3a9b_row7_col1\" class=\"data row7 col1\" >1588</td>\n",
       "      <td id=\"T_f3a9b_row7_col2\" class=\"data row7 col2\" >1606</td>\n",
       "      <td id=\"T_f3a9b_row7_col3\" class=\"data row7 col3\" >1766</td>\n",
       "      <td id=\"T_f3a9b_row7_col4\" class=\"data row7 col4\" >1763</td>\n",
       "      <td id=\"T_f3a9b_row7_col5\" class=\"data row7 col5\" >1688</td>\n",
       "      <td id=\"T_f3a9b_row7_col6\" class=\"data row7 col6\" >1538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f3a9b_level0_row8\" class=\"row_heading level0 row8\" >Instance 9</th>\n",
       "      <td id=\"T_f3a9b_row8_col0\" class=\"data row8 col0\" >1631</td>\n",
       "      <td id=\"T_f3a9b_row8_col1\" class=\"data row8 col1\" >1611</td>\n",
       "      <td id=\"T_f3a9b_row8_col2\" class=\"data row8 col2\" >1659</td>\n",
       "      <td id=\"T_f3a9b_row8_col3\" class=\"data row8 col3\" >1720</td>\n",
       "      <td id=\"T_f3a9b_row8_col4\" class=\"data row8 col4\" >1836</td>\n",
       "      <td id=\"T_f3a9b_row8_col5\" class=\"data row8 col5\" >1659</td>\n",
       "      <td id=\"T_f3a9b_row8_col6\" class=\"data row8 col6\" >1593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f3a9b_level0_row9\" class=\"row_heading level0 row9\" >Instance 10</th>\n",
       "      <td id=\"T_f3a9b_row9_col0\" class=\"data row9 col0\" >1631</td>\n",
       "      <td id=\"T_f3a9b_row9_col1\" class=\"data row9 col1\" >1631</td>\n",
       "      <td id=\"T_f3a9b_row9_col2\" class=\"data row9 col2\" >1652</td>\n",
       "      <td id=\"T_f3a9b_row9_col3\" class=\"data row9 col3\" >1884</td>\n",
       "      <td id=\"T_f3a9b_row9_col4\" class=\"data row9 col4\" >1898</td>\n",
       "      <td id=\"T_f3a9b_row9_col5\" class=\"data row9 col5\" >1702</td>\n",
       "      <td id=\"T_f3a9b_row9_col6\" class=\"data row9 col6\" >1591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x299ec7bfbd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(instances_20_10, makes_spans_20_10, study_ga, study_sa, cds, palmer, neh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 jobs 20 machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Temperature 0.00515377520732012:  10%|█         | 50/500 [05:25<48:53,  6.52s/it]   \n",
      "Temperature 0.00515377520732012:  10%|█         | 50/500 [06:15<56:16,  7.50s/it]   \n",
      "Temperature 0.00515377520732012:  10%|█         | 50/500 [06:48<1:01:16,  8.17s/it] \n",
      "Temperature 0.00515377520732012:  10%|█         | 50/500 [02:44<24:39,  3.29s/it] \n",
      "Temperature 0.00515377520732012:  10%|█         | 50/500 [12:08<1:49:12, 14.56s/it] \n",
      "Temperature 0.00515377520732012:  10%|█         | 50/500 [3:20:40<30:06:08, 240.82s/it]  \n",
      "Temperature 0.00515377520732012:  10%|█         | 50/500 [08:53<1:19:59, 10.67s/it] \n",
      "Temperature 0.00515377520732012:  10%|█         | 50/500 [02:55<26:18,  3.51s/it]   \n",
      "Temperature 0.00515377520732012:  10%|█         | 50/500 [02:33<23:02,  3.07s/it]   \n",
      "Temperature 0.00515377520732012:  10%|█         | 50/500 [05:01<45:17,  6.04s/it]   \n"
     ]
    }
   ],
   "source": [
    "instances_20_20 = load_tai(20,20)\n",
    "makes_spans_20_20 = []\n",
    "for instance in instances_20_20:\n",
    "    saga = LSAGA(instance, variety_degree=5)\n",
    "    saga.optim(T_min=0.005)\n",
    "    makes_spans_20_20.append(saga.make_span_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing heursitics\n",
      "tuning simulated annealing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 2363: 100%|██████████| 10/10 [00:00<00:00, 15.46it/s]\n",
      "Best trial: 4. Best value: 2147: 100%|██████████| 10/10 [00:00<00:00, 14.54it/s]\n",
      "Best trial: 2. Best value: 2388: 100%|██████████| 10/10 [00:00<00:00, 19.37it/s]\n",
      "Best trial: 3. Best value: 2294: 100%|██████████| 10/10 [00:01<00:00,  7.90it/s]\n",
      "Best trial: 8. Best value: 2352: 100%|██████████| 10/10 [00:00<00:00, 21.45it/s]\n",
      "Best trial: 8. Best value: 2289: 100%|██████████| 10/10 [00:00<00:00, 14.15it/s]\n",
      "Best trial: 4. Best value: 2339: 100%|██████████| 10/10 [00:00<00:00, 18.11it/s]\n",
      "Best trial: 5. Best value: 2240: 100%|██████████| 10/10 [00:00<00:00, 26.19it/s]\n",
      "Best trial: 9. Best value: 2284: 100%|██████████| 10/10 [00:00<00:00, 16.17it/s]\n",
      "Best trial: 5. Best value: 2268: 100%|██████████| 10/10 [00:00<00:00, 12.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning genetic algorithm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 2359: 100%|██████████| 10/10 [00:15<00:00,  1.52s/it]\n",
      "Best trial: 6. Best value: 2138: 100%|██████████| 10/10 [00:34<00:00,  3.44s/it]\n",
      "Best trial: 0. Best value: 2397: 100%|██████████| 10/10 [00:26<00:00,  2.60s/it]\n",
      "Best trial: 6. Best value: 2269: 100%|██████████| 10/10 [00:23<00:00,  2.35s/it]\n",
      "Best trial: 0. Best value: 2345: 100%|██████████| 10/10 [00:40<00:00,  4.09s/it]\n",
      "Best trial: 6. Best value: 2303: 100%|██████████| 10/10 [02:18<00:00, 13.86s/it]\n",
      "Best trial: 2. Best value: 2334: 100%|██████████| 10/10 [00:23<00:00,  2.40s/it]\n",
      "Best trial: 2. Best value: 2226: 100%|██████████| 10/10 [00:59<00:00,  5.92s/it]\n",
      "Best trial: 5. Best value: 2264: 100%|██████████| 10/10 [00:27<00:00,  2.72s/it]\n",
      "Best trial: 5. Best value: 2252: 100%|██████████| 10/10 [00:17<00:00,  1.74s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"executing heursitics\")\n",
    "cds, palmer, neh = exec_heur(instances_20_20)\n",
    "print(\"tuning simulated annealing\")\n",
    "study_sa = exec_sa(instances_20_20)\n",
    "print(\"tuning genetic algorithm\")\n",
    "study_ga = exec_ga(instances_20_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4932c  {\n",
       "  min-width: 110px;\n",
       "}\n",
       "#T_4932c th {\n",
       "  min-width: 110px;\n",
       "}\n",
       "#T_4932c_row0_col0, #T_4932c_row1_col0, #T_4932c_row2_col0, #T_4932c_row3_col0, #T_4932c_row4_col0, #T_4932c_row5_col0, #T_4932c_row6_col0, #T_4932c_row7_col0, #T_4932c_row7_col1, #T_4932c_row8_col0, #T_4932c_row9_col0 {\n",
       "  color: green;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_4932c_row0_col4, #T_4932c_row1_col4, #T_4932c_row2_col4, #T_4932c_row3_col4, #T_4932c_row4_col4, #T_4932c_row5_col4, #T_4932c_row6_col3, #T_4932c_row7_col4, #T_4932c_row8_col4, #T_4932c_row9_col4 {\n",
       "  color: red;\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4932c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4932c_level0_col0\" class=\"col_heading level0 col0\" >LSAGA</th>\n",
       "      <th id=\"T_4932c_level0_col1\" class=\"col_heading level0 col1\" >Genetic Algorithm</th>\n",
       "      <th id=\"T_4932c_level0_col2\" class=\"col_heading level0 col2\" >Simmulated annealing</th>\n",
       "      <th id=\"T_4932c_level0_col3\" class=\"col_heading level0 col3\" >CDS</th>\n",
       "      <th id=\"T_4932c_level0_col4\" class=\"col_heading level0 col4\" >Palmer</th>\n",
       "      <th id=\"T_4932c_level0_col5\" class=\"col_heading level0 col5\" >NEH</th>\n",
       "      <th id=\"T_4932c_level0_col6\" class=\"col_heading level0 col6\" >Upper bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4932c_level0_row0\" class=\"row_heading level0 row0\" >Instance 1</th>\n",
       "      <td id=\"T_4932c_row0_col0\" class=\"data row0 col0\" >2334</td>\n",
       "      <td id=\"T_4932c_row0_col1\" class=\"data row0 col1\" >2359</td>\n",
       "      <td id=\"T_4932c_row0_col2\" class=\"data row0 col2\" >2363</td>\n",
       "      <td id=\"T_4932c_row0_col3\" class=\"data row0 col3\" >2579</td>\n",
       "      <td id=\"T_4932c_row0_col4\" class=\"data row0 col4\" >2818</td>\n",
       "      <td id=\"T_4932c_row0_col5\" class=\"data row0 col5\" >2456</td>\n",
       "      <td id=\"T_4932c_row0_col6\" class=\"data row0 col6\" >2297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4932c_level0_row1\" class=\"row_heading level0 row1\" >Instance 2</th>\n",
       "      <td id=\"T_4932c_row1_col0\" class=\"data row1 col0\" >2136</td>\n",
       "      <td id=\"T_4932c_row1_col1\" class=\"data row1 col1\" >2138</td>\n",
       "      <td id=\"T_4932c_row1_col2\" class=\"data row1 col2\" >2147</td>\n",
       "      <td id=\"T_4932c_row1_col3\" class=\"data row1 col3\" >2285</td>\n",
       "      <td id=\"T_4932c_row1_col4\" class=\"data row1 col4\" >2331</td>\n",
       "      <td id=\"T_4932c_row1_col5\" class=\"data row1 col5\" >2197</td>\n",
       "      <td id=\"T_4932c_row1_col6\" class=\"data row1 col6\" >2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4932c_level0_row2\" class=\"row_heading level0 row2\" >Instance 3</th>\n",
       "      <td id=\"T_4932c_row2_col0\" class=\"data row2 col0\" >2360</td>\n",
       "      <td id=\"T_4932c_row2_col1\" class=\"data row2 col1\" >2397</td>\n",
       "      <td id=\"T_4932c_row2_col2\" class=\"data row2 col2\" >2388</td>\n",
       "      <td id=\"T_4932c_row2_col3\" class=\"data row2 col3\" >2565</td>\n",
       "      <td id=\"T_4932c_row2_col4\" class=\"data row2 col4\" >2678</td>\n",
       "      <td id=\"T_4932c_row2_col5\" class=\"data row2 col5\" >2493</td>\n",
       "      <td id=\"T_4932c_row2_col6\" class=\"data row2 col6\" >2326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4932c_level0_row3\" class=\"row_heading level0 row3\" >Instance 4</th>\n",
       "      <td id=\"T_4932c_row3_col0\" class=\"data row3 col0\" >2257</td>\n",
       "      <td id=\"T_4932c_row3_col1\" class=\"data row3 col1\" >2269</td>\n",
       "      <td id=\"T_4932c_row3_col2\" class=\"data row3 col2\" >2294</td>\n",
       "      <td id=\"T_4932c_row3_col3\" class=\"data row3 col3\" >2415</td>\n",
       "      <td id=\"T_4932c_row3_col4\" class=\"data row3 col4\" >2629</td>\n",
       "      <td id=\"T_4932c_row3_col5\" class=\"data row3 col5\" >2316</td>\n",
       "      <td id=\"T_4932c_row3_col6\" class=\"data row3 col6\" >2223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4932c_level0_row4\" class=\"row_heading level0 row4\" >Instance 5</th>\n",
       "      <td id=\"T_4932c_row4_col0\" class=\"data row4 col0\" >2327</td>\n",
       "      <td id=\"T_4932c_row4_col1\" class=\"data row4 col1\" >2345</td>\n",
       "      <td id=\"T_4932c_row4_col2\" class=\"data row4 col2\" >2352</td>\n",
       "      <td id=\"T_4932c_row4_col3\" class=\"data row4 col3\" >2506</td>\n",
       "      <td id=\"T_4932c_row4_col4\" class=\"data row4 col4\" >2704</td>\n",
       "      <td id=\"T_4932c_row4_col5\" class=\"data row4 col5\" >2436</td>\n",
       "      <td id=\"T_4932c_row4_col6\" class=\"data row4 col6\" >2291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4932c_level0_row5\" class=\"row_heading level0 row5\" >Instance 6</th>\n",
       "      <td id=\"T_4932c_row5_col0\" class=\"data row5 col0\" >2270</td>\n",
       "      <td id=\"T_4932c_row5_col1\" class=\"data row5 col1\" >2303</td>\n",
       "      <td id=\"T_4932c_row5_col2\" class=\"data row5 col2\" >2289</td>\n",
       "      <td id=\"T_4932c_row5_col3\" class=\"data row5 col3\" >2422</td>\n",
       "      <td id=\"T_4932c_row5_col4\" class=\"data row5 col4\" >2572</td>\n",
       "      <td id=\"T_4932c_row5_col5\" class=\"data row5 col5\" >2364</td>\n",
       "      <td id=\"T_4932c_row5_col6\" class=\"data row5 col6\" >2226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4932c_level0_row6\" class=\"row_heading level0 row6\" >Instance 7</th>\n",
       "      <td id=\"T_4932c_row6_col0\" class=\"data row6 col0\" >2322</td>\n",
       "      <td id=\"T_4932c_row6_col1\" class=\"data row6 col1\" >2334</td>\n",
       "      <td id=\"T_4932c_row6_col2\" class=\"data row6 col2\" >2339</td>\n",
       "      <td id=\"T_4932c_row6_col3\" class=\"data row6 col3\" >2489</td>\n",
       "      <td id=\"T_4932c_row6_col4\" class=\"data row6 col4\" >2456</td>\n",
       "      <td id=\"T_4932c_row6_col5\" class=\"data row6 col5\" >2406</td>\n",
       "      <td id=\"T_4932c_row6_col6\" class=\"data row6 col6\" >2273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4932c_level0_row7\" class=\"row_heading level0 row7\" >Instance 8</th>\n",
       "      <td id=\"T_4932c_row7_col0\" class=\"data row7 col0\" >2226</td>\n",
       "      <td id=\"T_4932c_row7_col1\" class=\"data row7 col1\" >2226</td>\n",
       "      <td id=\"T_4932c_row7_col2\" class=\"data row7 col2\" >2240</td>\n",
       "      <td id=\"T_4932c_row7_col3\" class=\"data row7 col3\" >2362</td>\n",
       "      <td id=\"T_4932c_row7_col4\" class=\"data row7 col4\" >2435</td>\n",
       "      <td id=\"T_4932c_row7_col5\" class=\"data row7 col5\" >2278</td>\n",
       "      <td id=\"T_4932c_row7_col6\" class=\"data row7 col6\" >2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4932c_level0_row8\" class=\"row_heading level0 row8\" >Instance 9</th>\n",
       "      <td id=\"T_4932c_row8_col0\" class=\"data row8 col0\" >2255</td>\n",
       "      <td id=\"T_4932c_row8_col1\" class=\"data row8 col1\" >2264</td>\n",
       "      <td id=\"T_4932c_row8_col2\" class=\"data row8 col2\" >2284</td>\n",
       "      <td id=\"T_4932c_row8_col3\" class=\"data row8 col3\" >2409</td>\n",
       "      <td id=\"T_4932c_row8_col4\" class=\"data row8 col4\" >2754</td>\n",
       "      <td id=\"T_4932c_row8_col5\" class=\"data row8 col5\" >2399</td>\n",
       "      <td id=\"T_4932c_row8_col6\" class=\"data row8 col6\" >2237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4932c_level0_row9\" class=\"row_heading level0 row9\" >Instance 10</th>\n",
       "      <td id=\"T_4932c_row9_col0\" class=\"data row9 col0\" >2212</td>\n",
       "      <td id=\"T_4932c_row9_col1\" class=\"data row9 col1\" >2252</td>\n",
       "      <td id=\"T_4932c_row9_col2\" class=\"data row9 col2\" >2268</td>\n",
       "      <td id=\"T_4932c_row9_col3\" class=\"data row9 col3\" >2439</td>\n",
       "      <td id=\"T_4932c_row9_col4\" class=\"data row9 col4\" >2633</td>\n",
       "      <td id=\"T_4932c_row9_col5\" class=\"data row9 col5\" >2352</td>\n",
       "      <td id=\"T_4932c_row9_col6\" class=\"data row9 col6\" >2178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x25c2b765c50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(instances_20_20, makes_spans_20_20, study_ga, study_sa, cds, palmer, neh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 jobs 5 machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Temperature 0.00515377520732012:  10%|█         | 50/500 [01:10<10:34,  1.41s/it] \n",
      "Temperature 0.00515377520732012:  10%|█         | 50/500 [10:01<1:30:11, 12.03s/it] \n",
      "Temperature 0.00515377520732012:  10%|█         | 50/500 [05:33<50:03,  6.68s/it]   \n",
      "Temperature 0.00515377520732012:  10%|█         | 50/500 [03:16<29:27,  3.93s/it]   \n",
      "Temperature 0.00515377520732012:  10%|█         | 50/500 [02:56<26:27,  3.53s/it] \n",
      "Temperature 0.00515377520732012:  10%|█         | 50/500 [02:22<21:20,  2.84s/it] \n",
      "Temperature 0.00515377520732012:  10%|█         | 50/500 [03:29<31:27,  4.19s/it]  \n",
      "Temperature 0.00515377520732012:  10%|█         | 50/500 [02:12<19:54,  2.65s/it]  \n",
      "Temperature 0.00515377520732012:  10%|█         | 50/500 [01:54<17:08,  2.29s/it] \n",
      "Temperature 0.00515377520732012:  10%|█         | 50/500 [03:40<33:07,  4.42s/it]  \n"
     ]
    }
   ],
   "source": [
    "instances_50_5 = load_tai(50,5)\n",
    "makes_spans_50_5 = []\n",
    "for instance in instances_50_5:\n",
    "    saga = LSAGA(instance, variety_degree=5)\n",
    "    saga.optim(T_min=0.005)\n",
    "    makes_spans_50_5.append(saga.make_span_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing heursitics\n",
      "tuning simulated annealing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 2735: 100%|██████████| 10/10 [00:00<00:00, 13.02it/s]\n",
      "Best trial: 1. Best value: 2890: 100%|██████████| 10/10 [00:01<00:00,  9.95it/s]\n",
      "Best trial: 5. Best value: 2648: 100%|██████████| 10/10 [00:00<00:00, 10.80it/s]\n",
      "Best trial: 9. Best value: 2802: 100%|██████████| 10/10 [00:00<00:00, 13.82it/s]\n",
      "Best trial: 6. Best value: 2891: 100%|██████████| 10/10 [00:00<00:00, 17.83it/s]\n",
      "Best trial: 4. Best value: 2849: 100%|██████████| 10/10 [00:01<00:00,  9.36it/s]\n",
      "Best trial: 7. Best value: 2746: 100%|██████████| 10/10 [00:00<00:00, 14.60it/s]\n",
      "Best trial: 0. Best value: 2707: 100%|██████████| 10/10 [00:00<00:00, 12.53it/s]\n",
      "Best trial: 6. Best value: 2592: 100%|██████████| 10/10 [00:00<00:00, 10.73it/s]\n",
      "Best trial: 0. Best value: 2815: 100%|██████████| 10/10 [00:01<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning genetic algorithm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 2735: 100%|██████████| 10/10 [00:32<00:00,  3.21s/it]\n",
      "Best trial: 0. Best value: 2863: 100%|██████████| 10/10 [00:22<00:00,  2.22s/it]\n",
      "Best trial: 3. Best value: 2630: 100%|██████████| 10/10 [00:19<00:00,  1.92s/it]\n",
      "Best trial: 6. Best value: 2778: 100%|██████████| 10/10 [00:23<00:00,  2.40s/it]\n",
      "Best trial: 4. Best value: 2864: 100%|██████████| 10/10 [00:28<00:00,  2.87s/it]\n",
      "Best trial: 9. Best value: 2835: 100%|██████████| 10/10 [00:15<00:00,  1.54s/it]\n",
      "Best trial: 6. Best value: 2738: 100%|██████████| 10/10 [00:26<00:00,  2.67s/it]\n",
      "Best trial: 8. Best value: 2705: 100%|██████████| 10/10 [00:32<00:00,  3.27s/it]\n",
      "Best trial: 6. Best value: 2568: 100%|██████████| 10/10 [00:27<00:00,  2.76s/it]\n",
      "Best trial: 9. Best value: 2783: 100%|██████████| 10/10 [00:54<00:00,  5.45s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"executing heursitics\")\n",
    "cds, palmer, neh = exec_heur(instances_50_5)\n",
    "print(\"tuning simulated annealing\")\n",
    "study_sa = exec_sa(instances_50_5)\n",
    "print(\"tuning genetic algorithm\")\n",
    "study_ga = exec_ga(instances_50_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e0d72  {\n",
       "  min-width: 110px;\n",
       "}\n",
       "#T_e0d72 th {\n",
       "  min-width: 110px;\n",
       "}\n",
       "#T_e0d72_row0_col0, #T_e0d72_row0_col1, #T_e0d72_row0_col2, #T_e0d72_row1_col0, #T_e0d72_row2_col0, #T_e0d72_row3_col0, #T_e0d72_row4_col0, #T_e0d72_row4_col1, #T_e0d72_row5_col0, #T_e0d72_row6_col0, #T_e0d72_row7_col0, #T_e0d72_row8_col0, #T_e0d72_row8_col1, #T_e0d72_row9_col0 {\n",
       "  color: green;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_e0d72_row0_col3, #T_e0d72_row1_col3, #T_e0d72_row2_col4, #T_e0d72_row3_col3, #T_e0d72_row4_col3, #T_e0d72_row5_col4, #T_e0d72_row6_col3, #T_e0d72_row7_col3, #T_e0d72_row8_col3, #T_e0d72_row9_col3 {\n",
       "  color: red;\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e0d72\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e0d72_level0_col0\" class=\"col_heading level0 col0\" >LSAGA</th>\n",
       "      <th id=\"T_e0d72_level0_col1\" class=\"col_heading level0 col1\" >Genetic Algorithm</th>\n",
       "      <th id=\"T_e0d72_level0_col2\" class=\"col_heading level0 col2\" >Simmulated annealing</th>\n",
       "      <th id=\"T_e0d72_level0_col3\" class=\"col_heading level0 col3\" >CDS</th>\n",
       "      <th id=\"T_e0d72_level0_col4\" class=\"col_heading level0 col4\" >Palmer</th>\n",
       "      <th id=\"T_e0d72_level0_col5\" class=\"col_heading level0 col5\" >NEH</th>\n",
       "      <th id=\"T_e0d72_level0_col6\" class=\"col_heading level0 col6\" >Upper bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e0d72_level0_row0\" class=\"row_heading level0 row0\" >Instance 1</th>\n",
       "      <td id=\"T_e0d72_row0_col0\" class=\"data row0 col0\" >2735</td>\n",
       "      <td id=\"T_e0d72_row0_col1\" class=\"data row0 col1\" >2735</td>\n",
       "      <td id=\"T_e0d72_row0_col2\" class=\"data row0 col2\" >2735</td>\n",
       "      <td id=\"T_e0d72_row0_col3\" class=\"data row0 col3\" >2883</td>\n",
       "      <td id=\"T_e0d72_row0_col4\" class=\"data row0 col4\" >2774</td>\n",
       "      <td id=\"T_e0d72_row0_col5\" class=\"data row0 col5\" >2745</td>\n",
       "      <td id=\"T_e0d72_row0_col6\" class=\"data row0 col6\" >2724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0d72_level0_row1\" class=\"row_heading level0 row1\" >Instance 2</th>\n",
       "      <td id=\"T_e0d72_row1_col0\" class=\"data row1 col0\" >2848</td>\n",
       "      <td id=\"T_e0d72_row1_col1\" class=\"data row1 col1\" >2863</td>\n",
       "      <td id=\"T_e0d72_row1_col2\" class=\"data row1 col2\" >2890</td>\n",
       "      <td id=\"T_e0d72_row1_col3\" class=\"data row1 col3\" >3032</td>\n",
       "      <td id=\"T_e0d72_row1_col4\" class=\"data row1 col4\" >3014</td>\n",
       "      <td id=\"T_e0d72_row1_col5\" class=\"data row1 col5\" >2943</td>\n",
       "      <td id=\"T_e0d72_row1_col6\" class=\"data row1 col6\" >2834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0d72_level0_row2\" class=\"row_heading level0 row2\" >Instance 3</th>\n",
       "      <td id=\"T_e0d72_row2_col0\" class=\"data row2 col0\" >2624</td>\n",
       "      <td id=\"T_e0d72_row2_col1\" class=\"data row2 col1\" >2630</td>\n",
       "      <td id=\"T_e0d72_row2_col2\" class=\"data row2 col2\" >2648</td>\n",
       "      <td id=\"T_e0d72_row2_col3\" class=\"data row2 col3\" >2714</td>\n",
       "      <td id=\"T_e0d72_row2_col4\" class=\"data row2 col4\" >2777</td>\n",
       "      <td id=\"T_e0d72_row2_col5\" class=\"data row2 col5\" >2712</td>\n",
       "      <td id=\"T_e0d72_row2_col6\" class=\"data row2 col6\" >2621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0d72_level0_row3\" class=\"row_heading level0 row3\" >Instance 4</th>\n",
       "      <td id=\"T_e0d72_row3_col0\" class=\"data row3 col0\" >2770</td>\n",
       "      <td id=\"T_e0d72_row3_col1\" class=\"data row3 col1\" >2778</td>\n",
       "      <td id=\"T_e0d72_row3_col2\" class=\"data row3 col2\" >2802</td>\n",
       "      <td id=\"T_e0d72_row3_col3\" class=\"data row3 col3\" >2884</td>\n",
       "      <td id=\"T_e0d72_row3_col4\" class=\"data row3 col4\" >2860</td>\n",
       "      <td id=\"T_e0d72_row3_col5\" class=\"data row3 col5\" >2855</td>\n",
       "      <td id=\"T_e0d72_row3_col6\" class=\"data row3 col6\" >2751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0d72_level0_row4\" class=\"row_heading level0 row4\" >Instance 5</th>\n",
       "      <td id=\"T_e0d72_row4_col0\" class=\"data row4 col0\" >2864</td>\n",
       "      <td id=\"T_e0d72_row4_col1\" class=\"data row4 col1\" >2864</td>\n",
       "      <td id=\"T_e0d72_row4_col2\" class=\"data row4 col2\" >2891</td>\n",
       "      <td id=\"T_e0d72_row4_col3\" class=\"data row4 col3\" >3038</td>\n",
       "      <td id=\"T_e0d72_row4_col4\" class=\"data row4 col4\" >2963</td>\n",
       "      <td id=\"T_e0d72_row4_col5\" class=\"data row4 col5\" >2929</td>\n",
       "      <td id=\"T_e0d72_row4_col6\" class=\"data row4 col6\" >2863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0d72_level0_row5\" class=\"row_heading level0 row5\" >Instance 6</th>\n",
       "      <td id=\"T_e0d72_row5_col0\" class=\"data row5 col0\" >2831</td>\n",
       "      <td id=\"T_e0d72_row5_col1\" class=\"data row5 col1\" >2835</td>\n",
       "      <td id=\"T_e0d72_row5_col2\" class=\"data row5 col2\" >2849</td>\n",
       "      <td id=\"T_e0d72_row5_col3\" class=\"data row5 col3\" >3031</td>\n",
       "      <td id=\"T_e0d72_row5_col4\" class=\"data row5 col4\" >3090</td>\n",
       "      <td id=\"T_e0d72_row5_col5\" class=\"data row5 col5\" >2938</td>\n",
       "      <td id=\"T_e0d72_row5_col6\" class=\"data row5 col6\" >2829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0d72_level0_row6\" class=\"row_heading level0 row6\" >Instance 7</th>\n",
       "      <td id=\"T_e0d72_row6_col0\" class=\"data row6 col0\" >2732</td>\n",
       "      <td id=\"T_e0d72_row6_col1\" class=\"data row6 col1\" >2738</td>\n",
       "      <td id=\"T_e0d72_row6_col2\" class=\"data row6 col2\" >2746</td>\n",
       "      <td id=\"T_e0d72_row6_col3\" class=\"data row6 col3\" >2978</td>\n",
       "      <td id=\"T_e0d72_row6_col4\" class=\"data row6 col4\" >2845</td>\n",
       "      <td id=\"T_e0d72_row6_col5\" class=\"data row6 col5\" >2800</td>\n",
       "      <td id=\"T_e0d72_row6_col6\" class=\"data row6 col6\" >2725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0d72_level0_row7\" class=\"row_heading level0 row7\" >Instance 8</th>\n",
       "      <td id=\"T_e0d72_row7_col0\" class=\"data row7 col0\" >2700</td>\n",
       "      <td id=\"T_e0d72_row7_col1\" class=\"data row7 col1\" >2705</td>\n",
       "      <td id=\"T_e0d72_row7_col2\" class=\"data row7 col2\" >2707</td>\n",
       "      <td id=\"T_e0d72_row7_col3\" class=\"data row7 col3\" >2867</td>\n",
       "      <td id=\"T_e0d72_row7_col4\" class=\"data row7 col4\" >2826</td>\n",
       "      <td id=\"T_e0d72_row7_col5\" class=\"data row7 col5\" >2795</td>\n",
       "      <td id=\"T_e0d72_row7_col6\" class=\"data row7 col6\" >2683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0d72_level0_row8\" class=\"row_heading level0 row8\" >Instance 9</th>\n",
       "      <td id=\"T_e0d72_row8_col0\" class=\"data row8 col0\" >2568</td>\n",
       "      <td id=\"T_e0d72_row8_col1\" class=\"data row8 col1\" >2568</td>\n",
       "      <td id=\"T_e0d72_row8_col2\" class=\"data row8 col2\" >2592</td>\n",
       "      <td id=\"T_e0d72_row8_col3\" class=\"data row8 col3\" >2784</td>\n",
       "      <td id=\"T_e0d72_row8_col4\" class=\"data row8 col4\" >2733</td>\n",
       "      <td id=\"T_e0d72_row8_col5\" class=\"data row8 col5\" >2683</td>\n",
       "      <td id=\"T_e0d72_row8_col6\" class=\"data row8 col6\" >2552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0d72_level0_row9\" class=\"row_heading level0 row9\" >Instance 10</th>\n",
       "      <td id=\"T_e0d72_row9_col0\" class=\"data row9 col0\" >2782</td>\n",
       "      <td id=\"T_e0d72_row9_col1\" class=\"data row9 col1\" >2783</td>\n",
       "      <td id=\"T_e0d72_row9_col2\" class=\"data row9 col2\" >2815</td>\n",
       "      <td id=\"T_e0d72_row9_col3\" class=\"data row9 col3\" >3000</td>\n",
       "      <td id=\"T_e0d72_row9_col4\" class=\"data row9 col4\" >2915</td>\n",
       "      <td id=\"T_e0d72_row9_col5\" class=\"data row9 col5\" >2878</td>\n",
       "      <td id=\"T_e0d72_row9_col6\" class=\"data row9 col6\" >2782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x25c2c8f5a10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(instances_50_5, makes_spans_50_5, study_ga, study_sa, cds, palmer, neh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 jobs 10 machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [09:55<1:45:26, 13.84s/it]  \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [04:32<48:19,  6.35s/it]   \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [04:31<48:06,  6.32s/it]   \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [09:43<1:43:26, 13.58s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [02:31<26:49,  3.52s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [04:27<47:19,  6.21s/it]  \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [05:56<1:03:08,  8.29s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [03:34<38:03,  5.00s/it]   \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [04:31<48:01,  6.30s/it]  \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [08:00<1:25:07, 11.18s/it] \n"
     ]
    }
   ],
   "source": [
    "instances_50_10 = load_tai(50,10)\n",
    "makes_spans_50_10 = []\n",
    "for instance in instances_50_10:\n",
    "    saga = LSAGA(instance, variety_degree=3)\n",
    "    saga.optim(T_min=0.01)\n",
    "    makes_spans_50_10.append(saga.make_span_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing heursitics\n",
      "tuning simulated annealing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 3186: 100%|██████████| 10/10 [00:01<00:00,  5.50it/s]\n",
      "Best trial: 6. Best value: 3014: 100%|██████████| 10/10 [00:06<00:00,  1.55it/s]\n",
      "Best trial: 1. Best value: 2957: 100%|██████████| 10/10 [00:06<00:00,  1.53it/s]\n",
      "Best trial: 7. Best value: 3192: 100%|██████████| 10/10 [00:04<00:00,  2.36it/s]\n",
      "Best trial: 4. Best value: 3183: 100%|██████████| 10/10 [00:01<00:00,  6.60it/s]\n",
      "Best trial: 5. Best value: 3158: 100%|██████████| 10/10 [00:01<00:00,  6.53it/s]\n",
      "Best trial: 3. Best value: 3232: 100%|██████████| 10/10 [00:03<00:00,  3.01it/s]\n",
      "Best trial: 4. Best value: 3144: 100%|██████████| 10/10 [00:04<00:00,  2.06it/s]\n",
      "Best trial: 4. Best value: 2978: 100%|██████████| 10/10 [00:05<00:00,  1.92it/s]\n",
      "Best trial: 6. Best value: 3195: 100%|██████████| 10/10 [00:02<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning genetic algorithm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 3151: 100%|██████████| 10/10 [02:23<00:00, 14.35s/it]\n",
      "Best trial: 0. Best value: 2972: 100%|██████████| 10/10 [04:10<00:00, 25.07s/it]\n",
      "Best trial: 5. Best value: 2984: 100%|██████████| 10/10 [03:34<00:00, 21.45s/it]\n",
      "Best trial: 3. Best value: 3137: 100%|██████████| 10/10 [01:36<00:00,  9.70s/it]\n",
      "Best trial: 5. Best value: 3066: 100%|██████████| 10/10 [01:40<00:00, 10.05s/it]\n",
      "Best trial: 5. Best value: 3118: 100%|██████████| 10/10 [01:34<00:00,  9.40s/it]\n",
      "Best trial: 2. Best value: 3197: 100%|██████████| 10/10 [01:43<00:00, 10.32s/it]\n",
      "Best trial: 0. Best value: 3106: 100%|██████████| 10/10 [01:39<00:00,  9.93s/it]\n",
      "Best trial: 3. Best value: 2994: 100%|██████████| 10/10 [01:29<00:00,  8.97s/it]\n",
      "Best trial: 9. Best value: 3182: 100%|██████████| 10/10 [02:29<00:00, 14.90s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"executing heursitics\")\n",
    "cds, palmer, neh = exec_heur(instances_50_10)\n",
    "print(\"tuning simulated annealing\")\n",
    "study_sa = exec_sa(instances_50_10)\n",
    "print(\"tuning genetic algorithm\")\n",
    "study_ga = exec_ga(instances_50_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a9972  {\n",
       "  min-width: 110px;\n",
       "}\n",
       "#T_a9972 th {\n",
       "  min-width: 110px;\n",
       "}\n",
       "#T_a9972_row0_col0, #T_a9972_row1_col1, #T_a9972_row2_col0, #T_a9972_row3_col0, #T_a9972_row4_col1, #T_a9972_row5_col0, #T_a9972_row6_col0, #T_a9972_row7_col0, #T_a9972_row8_col2, #T_a9972_row9_col0 {\n",
       "  color: green;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_a9972_row0_col4, #T_a9972_row1_col4, #T_a9972_row2_col4, #T_a9972_row3_col4, #T_a9972_row4_col4, #T_a9972_row5_col3, #T_a9972_row6_col3, #T_a9972_row7_col4, #T_a9972_row8_col4, #T_a9972_row9_col3 {\n",
       "  color: red;\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a9972\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a9972_level0_col0\" class=\"col_heading level0 col0\" >LSAGA</th>\n",
       "      <th id=\"T_a9972_level0_col1\" class=\"col_heading level0 col1\" >Genetic Algorithm</th>\n",
       "      <th id=\"T_a9972_level0_col2\" class=\"col_heading level0 col2\" >Simmulated annealing</th>\n",
       "      <th id=\"T_a9972_level0_col3\" class=\"col_heading level0 col3\" >CDS</th>\n",
       "      <th id=\"T_a9972_level0_col4\" class=\"col_heading level0 col4\" >Palmer</th>\n",
       "      <th id=\"T_a9972_level0_col5\" class=\"col_heading level0 col5\" >NEH</th>\n",
       "      <th id=\"T_a9972_level0_col6\" class=\"col_heading level0 col6\" >Upper bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a9972_level0_row0\" class=\"row_heading level0 row0\" >Instance 1</th>\n",
       "      <td id=\"T_a9972_row0_col0\" class=\"data row0 col0\" >3096</td>\n",
       "      <td id=\"T_a9972_row0_col1\" class=\"data row0 col1\" >3151</td>\n",
       "      <td id=\"T_a9972_row0_col2\" class=\"data row0 col2\" >3186</td>\n",
       "      <td id=\"T_a9972_row0_col3\" class=\"data row0 col3\" >3382</td>\n",
       "      <td id=\"T_a9972_row0_col4\" class=\"data row0 col4\" >3461</td>\n",
       "      <td id=\"T_a9972_row0_col5\" class=\"data row0 col5\" >3249</td>\n",
       "      <td id=\"T_a9972_row0_col6\" class=\"data row0 col6\" >3025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9972_level0_row1\" class=\"row_heading level0 row1\" >Instance 2</th>\n",
       "      <td id=\"T_a9972_row1_col0\" class=\"data row1 col0\" >2987</td>\n",
       "      <td id=\"T_a9972_row1_col1\" class=\"data row1 col1\" >2972</td>\n",
       "      <td id=\"T_a9972_row1_col2\" class=\"data row1 col2\" >3014</td>\n",
       "      <td id=\"T_a9972_row1_col3\" class=\"data row1 col3\" >3263</td>\n",
       "      <td id=\"T_a9972_row1_col4\" class=\"data row1 col4\" >3313</td>\n",
       "      <td id=\"T_a9972_row1_col5\" class=\"data row1 col5\" >3145</td>\n",
       "      <td id=\"T_a9972_row1_col6\" class=\"data row1 col6\" >2892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9972_level0_row2\" class=\"row_heading level0 row2\" >Instance 3</th>\n",
       "      <td id=\"T_a9972_row2_col0\" class=\"data row2 col0\" >2936</td>\n",
       "      <td id=\"T_a9972_row2_col1\" class=\"data row2 col1\" >2984</td>\n",
       "      <td id=\"T_a9972_row2_col2\" class=\"data row2 col2\" >2957</td>\n",
       "      <td id=\"T_a9972_row2_col3\" class=\"data row2 col3\" >3287</td>\n",
       "      <td id=\"T_a9972_row2_col4\" class=\"data row2 col4\" >3335</td>\n",
       "      <td id=\"T_a9972_row2_col5\" class=\"data row2 col5\" >3125</td>\n",
       "      <td id=\"T_a9972_row2_col6\" class=\"data row2 col6\" >2864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9972_level0_row3\" class=\"row_heading level0 row3\" >Instance 4</th>\n",
       "      <td id=\"T_a9972_row3_col0\" class=\"data row3 col0\" >3135</td>\n",
       "      <td id=\"T_a9972_row3_col1\" class=\"data row3 col1\" >3137</td>\n",
       "      <td id=\"T_a9972_row3_col2\" class=\"data row3 col2\" >3192</td>\n",
       "      <td id=\"T_a9972_row3_col3\" class=\"data row3 col3\" >3393</td>\n",
       "      <td id=\"T_a9972_row3_col4\" class=\"data row3 col4\" >3511</td>\n",
       "      <td id=\"T_a9972_row3_col5\" class=\"data row3 col5\" >3214</td>\n",
       "      <td id=\"T_a9972_row3_col6\" class=\"data row3 col6\" >3064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9972_level0_row4\" class=\"row_heading level0 row4\" >Instance 5</th>\n",
       "      <td id=\"T_a9972_row4_col0\" class=\"data row4 col0\" >3072</td>\n",
       "      <td id=\"T_a9972_row4_col1\" class=\"data row4 col1\" >3066</td>\n",
       "      <td id=\"T_a9972_row4_col2\" class=\"data row4 col2\" >3183</td>\n",
       "      <td id=\"T_a9972_row4_col3\" class=\"data row4 col3\" >3375</td>\n",
       "      <td id=\"T_a9972_row4_col4\" class=\"data row4 col4\" >3427</td>\n",
       "      <td id=\"T_a9972_row4_col5\" class=\"data row4 col5\" >3222</td>\n",
       "      <td id=\"T_a9972_row4_col6\" class=\"data row4 col6\" >2986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9972_level0_row5\" class=\"row_heading level0 row5\" >Instance 6</th>\n",
       "      <td id=\"T_a9972_row5_col0\" class=\"data row5 col0\" >3079</td>\n",
       "      <td id=\"T_a9972_row5_col1\" class=\"data row5 col1\" >3118</td>\n",
       "      <td id=\"T_a9972_row5_col2\" class=\"data row5 col2\" >3158</td>\n",
       "      <td id=\"T_a9972_row5_col3\" class=\"data row5 col3\" >3400</td>\n",
       "      <td id=\"T_a9972_row5_col4\" class=\"data row5 col4\" >3318</td>\n",
       "      <td id=\"T_a9972_row5_col5\" class=\"data row5 col5\" >3246</td>\n",
       "      <td id=\"T_a9972_row5_col6\" class=\"data row5 col6\" >3006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9972_level0_row6\" class=\"row_heading level0 row6\" >Instance 7</th>\n",
       "      <td id=\"T_a9972_row6_col0\" class=\"data row6 col0\" >3175</td>\n",
       "      <td id=\"T_a9972_row6_col1\" class=\"data row6 col1\" >3197</td>\n",
       "      <td id=\"T_a9972_row6_col2\" class=\"data row6 col2\" >3232</td>\n",
       "      <td id=\"T_a9972_row6_col3\" class=\"data row6 col3\" >3530</td>\n",
       "      <td id=\"T_a9972_row6_col4\" class=\"data row6 col4\" >3457</td>\n",
       "      <td id=\"T_a9972_row6_col5\" class=\"data row6 col5\" >3270</td>\n",
       "      <td id=\"T_a9972_row6_col6\" class=\"data row6 col6\" >3107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9972_level0_row7\" class=\"row_heading level0 row7\" >Instance 8</th>\n",
       "      <td id=\"T_a9972_row7_col0\" class=\"data row7 col0\" >3104</td>\n",
       "      <td id=\"T_a9972_row7_col1\" class=\"data row7 col1\" >3106</td>\n",
       "      <td id=\"T_a9972_row7_col2\" class=\"data row7 col2\" >3144</td>\n",
       "      <td id=\"T_a9972_row7_col3\" class=\"data row7 col3\" >3371</td>\n",
       "      <td id=\"T_a9972_row7_col4\" class=\"data row7 col4\" >3382</td>\n",
       "      <td id=\"T_a9972_row7_col5\" class=\"data row7 col5\" >3219</td>\n",
       "      <td id=\"T_a9972_row7_col6\" class=\"data row7 col6\" >3039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9972_level0_row8\" class=\"row_heading level0 row8\" >Instance 9</th>\n",
       "      <td id=\"T_a9972_row8_col0\" class=\"data row8 col0\" >2982</td>\n",
       "      <td id=\"T_a9972_row8_col1\" class=\"data row8 col1\" >2994</td>\n",
       "      <td id=\"T_a9972_row8_col2\" class=\"data row8 col2\" >2978</td>\n",
       "      <td id=\"T_a9972_row8_col3\" class=\"data row8 col3\" >3251</td>\n",
       "      <td id=\"T_a9972_row8_col4\" class=\"data row8 col4\" >3414</td>\n",
       "      <td id=\"T_a9972_row8_col5\" class=\"data row8 col5\" >3096</td>\n",
       "      <td id=\"T_a9972_row8_col6\" class=\"data row8 col6\" >2902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9972_level0_row9\" class=\"row_heading level0 row9\" >Instance 10</th>\n",
       "      <td id=\"T_a9972_row9_col0\" class=\"data row9 col0\" >3169</td>\n",
       "      <td id=\"T_a9972_row9_col1\" class=\"data row9 col1\" >3182</td>\n",
       "      <td id=\"T_a9972_row9_col2\" class=\"data row9 col2\" >3195</td>\n",
       "      <td id=\"T_a9972_row9_col3\" class=\"data row9 col3\" >3429</td>\n",
       "      <td id=\"T_a9972_row9_col4\" class=\"data row9 col4\" >3404</td>\n",
       "      <td id=\"T_a9972_row9_col5\" class=\"data row9 col5\" >3223</td>\n",
       "      <td id=\"T_a9972_row9_col6\" class=\"data row9 col6\" >3091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x25c2d408c10>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(instances_50_10, makes_spans_50_10, study_ga, study_sa, cds, palmer, neh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these first 5 configurations studies, it appears that our proposed hyper heuristic shows promising results as it has often outperformed the other heuristics for the different instances. We can also notice that for the instances where it didn't perform as the best algorithm, it still ranked pretty well in the overall ranking.\n",
    "\n",
    "These results seem to encourage the idea of using a simulated annealing meta heuristic for the top level with a learning mecanism for the neighbor selection during exploration as proposed in our method. But still, further exploration with the rest of the taillard configurations remains necessary to fully asses tha quality of our solution. \n",
    "\n",
    "Also, as during these demos the hyper-parameters of the top level weren't fine tuned (as it would have taken more time than allowed for this first study), it seems reasonable to expect a significant improvement if the simulated annealing hyper-parameters were studied more thoroughly, especially for the variety-degree hyper-parameter (the minimum number of dimensions in the GA hyper-parameters space to change at neighbor generation) and the length_palier hyper-parameter (the number of iterations during which the temperature remains constant, by default =1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "50 jobs 20 machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [06:26<1:08:31,  9.00s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [18:28<3:16:20, 25.78s/it]  \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [05:07<54:31,  7.16s/it]  \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [16:29<2:55:11, 23.00s/it]  \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [02:56<31:13,  4.10s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [04:56<52:29,  6.89s/it]   \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [07:18<1:17:36, 10.19s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [04:48<51:03,  6.70s/it]   \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [07:09<1:16:08, 10.00s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [04:24<46:51,  6.15s/it]   \n"
     ]
    }
   ],
   "source": [
    "instances_50_20 = load_tai(50,20)\n",
    "makes_spans_50_20 = []\n",
    "for instance in instances_50_20:\n",
    "    saga = LSAGA(instance, variety_degree=5)\n",
    "    saga.optim(T_min=0.01)\n",
    "    makes_spans_50_20.append(saga.make_span_star)\n",
    "with open(\"lsaga_makes_spans_50_20.txt\",\"w\") as f:\n",
    "    for make_span in makes_spans_50_20:\n",
    "        f.write(str(make_span)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing heursitics\n",
      "tuning simulated annealing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 4091: 100%|██████████| 10/10 [00:03<00:00,  3.16it/s]\n",
      "Best trial: 0. Best value: 4007: 100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n",
      "Best trial: 2. Best value: 3877: 100%|██████████| 10/10 [00:01<00:00,  5.33it/s]\n",
      "Best trial: 0. Best value: 4006: 100%|██████████| 10/10 [00:06<00:00,  1.44it/s]\n",
      "Best trial: 6. Best value: 3851: 100%|██████████| 10/10 [00:06<00:00,  1.48it/s]\n",
      "Best trial: 2. Best value: 3910: 100%|██████████| 10/10 [00:03<00:00,  2.93it/s]\n",
      "Best trial: 6. Best value: 3945: 100%|██████████| 10/10 [00:05<00:00,  1.83it/s]\n",
      "Best trial: 4. Best value: 4035: 100%|██████████| 10/10 [00:02<00:00,  3.45it/s]\n",
      "Best trial: 2. Best value: 3999: 100%|██████████| 10/10 [00:06<00:00,  1.53it/s]\n",
      "Best trial: 0. Best value: 3982: 100%|██████████| 10/10 [00:04<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning genetic algorithm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 4053: 100%|██████████| 10/10 [01:06<00:00,  6.65s/it]\n",
      "Best trial: 2. Best value: 3952: 100%|██████████| 10/10 [01:26<00:00,  8.69s/it]\n",
      "Best trial: 8. Best value: 3866: 100%|██████████| 10/10 [01:52<00:00, 11.22s/it]\n",
      "Best trial: 3. Best value: 3960: 100%|██████████| 10/10 [04:07<00:00, 24.75s/it]\n",
      "Best trial: 8. Best value: 3841: 100%|██████████| 10/10 [02:00<00:00, 12.09s/it]\n",
      "Best trial: 7. Best value: 3890: 100%|██████████| 10/10 [01:01<00:00,  6.17s/it]\n",
      "Best trial: 6. Best value: 3888: 100%|██████████| 10/10 [01:58<00:00, 11.82s/it]\n",
      "Best trial: 5. Best value: 3891: 100%|██████████| 10/10 [05:26<00:00, 32.62s/it]\n",
      "Best trial: 8. Best value: 3953: 100%|██████████| 10/10 [05:11<00:00, 31.11s/it]\n",
      "Best trial: 7. Best value: 3916: 100%|██████████| 10/10 [05:46<00:00, 34.64s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"executing heursitics\")\n",
    "cds, palmer, neh = exec_heur(instances_50_20)\n",
    "print(\"tuning simulated annealing\")\n",
    "study_sa = exec_sa(instances_50_20)\n",
    "print(\"tuning genetic algorithm\")\n",
    "study_ga = exec_ga(instances_50_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_44e34  {\n",
       "  min-width: 110px;\n",
       "}\n",
       "#T_44e34 th {\n",
       "  min-width: 110px;\n",
       "}\n",
       "#T_44e34_row0_col0, #T_44e34_row1_col0, #T_44e34_row2_col0, #T_44e34_row2_col1, #T_44e34_row3_col0, #T_44e34_row4_col0, #T_44e34_row5_col0, #T_44e34_row6_col1, #T_44e34_row7_col1, #T_44e34_row8_col0, #T_44e34_row9_col1 {\n",
       "  color: green;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_44e34_row0_col3, #T_44e34_row1_col4, #T_44e34_row2_col4, #T_44e34_row3_col3, #T_44e34_row4_col4, #T_44e34_row5_col4, #T_44e34_row6_col4, #T_44e34_row7_col4, #T_44e34_row8_col4, #T_44e34_row9_col3 {\n",
       "  color: red;\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_44e34\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_44e34_level0_col0\" class=\"col_heading level0 col0\" >LSAGA</th>\n",
       "      <th id=\"T_44e34_level0_col1\" class=\"col_heading level0 col1\" >Genetic Algorithm</th>\n",
       "      <th id=\"T_44e34_level0_col2\" class=\"col_heading level0 col2\" >Simmulated annealing</th>\n",
       "      <th id=\"T_44e34_level0_col3\" class=\"col_heading level0 col3\" >CDS</th>\n",
       "      <th id=\"T_44e34_level0_col4\" class=\"col_heading level0 col4\" >Palmer</th>\n",
       "      <th id=\"T_44e34_level0_col5\" class=\"col_heading level0 col5\" >NEH</th>\n",
       "      <th id=\"T_44e34_level0_col6\" class=\"col_heading level0 col6\" >Upper bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_44e34_level0_row0\" class=\"row_heading level0 row0\" >Instance 1</th>\n",
       "      <td id=\"T_44e34_row0_col0\" class=\"data row0 col0\" >4036</td>\n",
       "      <td id=\"T_44e34_row0_col1\" class=\"data row0 col1\" >4053</td>\n",
       "      <td id=\"T_44e34_row0_col2\" class=\"data row0 col2\" >4091</td>\n",
       "      <td id=\"T_44e34_row0_col3\" class=\"data row0 col3\" >4319</td>\n",
       "      <td id=\"T_44e34_row0_col4\" class=\"data row0 col4\" >4272</td>\n",
       "      <td id=\"T_44e34_row0_col5\" class=\"data row0 col5\" >4164</td>\n",
       "      <td id=\"T_44e34_row0_col6\" class=\"data row0 col6\" >3875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44e34_level0_row1\" class=\"row_heading level0 row1\" >Instance 2</th>\n",
       "      <td id=\"T_44e34_row1_col0\" class=\"data row1 col0\" >3914</td>\n",
       "      <td id=\"T_44e34_row1_col1\" class=\"data row1 col1\" >3952</td>\n",
       "      <td id=\"T_44e34_row1_col2\" class=\"data row1 col2\" >4007</td>\n",
       "      <td id=\"T_44e34_row1_col3\" class=\"data row1 col3\" >4216</td>\n",
       "      <td id=\"T_44e34_row1_col4\" class=\"data row1 col4\" >4303</td>\n",
       "      <td id=\"T_44e34_row1_col5\" class=\"data row1 col5\" >4020</td>\n",
       "      <td id=\"T_44e34_row1_col6\" class=\"data row1 col6\" >3715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44e34_level0_row2\" class=\"row_heading level0 row2\" >Instance 3</th>\n",
       "      <td id=\"T_44e34_row2_col0\" class=\"data row2 col0\" >3866</td>\n",
       "      <td id=\"T_44e34_row2_col1\" class=\"data row2 col1\" >3866</td>\n",
       "      <td id=\"T_44e34_row2_col2\" class=\"data row2 col2\" >3877</td>\n",
       "      <td id=\"T_44e34_row2_col3\" class=\"data row2 col3\" >4203</td>\n",
       "      <td id=\"T_44e34_row2_col4\" class=\"data row2 col4\" >4210</td>\n",
       "      <td id=\"T_44e34_row2_col5\" class=\"data row2 col5\" >3877</td>\n",
       "      <td id=\"T_44e34_row2_col6\" class=\"data row2 col6\" >3668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44e34_level0_row3\" class=\"row_heading level0 row3\" >Instance 4</th>\n",
       "      <td id=\"T_44e34_row3_col0\" class=\"data row3 col0\" >3908</td>\n",
       "      <td id=\"T_44e34_row3_col1\" class=\"data row3 col1\" >3960</td>\n",
       "      <td id=\"T_44e34_row3_col2\" class=\"data row3 col2\" >4006</td>\n",
       "      <td id=\"T_44e34_row3_col3\" class=\"data row3 col3\" >4256</td>\n",
       "      <td id=\"T_44e34_row3_col4\" class=\"data row3 col4\" >4233</td>\n",
       "      <td id=\"T_44e34_row3_col5\" class=\"data row3 col5\" >4063</td>\n",
       "      <td id=\"T_44e34_row3_col6\" class=\"data row3 col6\" >3752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44e34_level0_row4\" class=\"row_heading level0 row4\" >Instance 5</th>\n",
       "      <td id=\"T_44e34_row4_col0\" class=\"data row4 col0\" >3801</td>\n",
       "      <td id=\"T_44e34_row4_col1\" class=\"data row4 col1\" >3841</td>\n",
       "      <td id=\"T_44e34_row4_col2\" class=\"data row4 col2\" >3851</td>\n",
       "      <td id=\"T_44e34_row4_col3\" class=\"data row4 col3\" >4180</td>\n",
       "      <td id=\"T_44e34_row4_col4\" class=\"data row4 col4\" >4376</td>\n",
       "      <td id=\"T_44e34_row4_col5\" class=\"data row4 col5\" >3878</td>\n",
       "      <td id=\"T_44e34_row4_col6\" class=\"data row4 col6\" >3635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44e34_level0_row5\" class=\"row_heading level0 row5\" >Instance 6</th>\n",
       "      <td id=\"T_44e34_row5_col0\" class=\"data row5 col0\" >3873</td>\n",
       "      <td id=\"T_44e34_row5_col1\" class=\"data row5 col1\" >3890</td>\n",
       "      <td id=\"T_44e34_row5_col2\" class=\"data row5 col2\" >3910</td>\n",
       "      <td id=\"T_44e34_row5_col3\" class=\"data row5 col3\" >4238</td>\n",
       "      <td id=\"T_44e34_row5_col4\" class=\"data row5 col4\" >4312</td>\n",
       "      <td id=\"T_44e34_row5_col5\" class=\"data row5 col5\" >3957</td>\n",
       "      <td id=\"T_44e34_row5_col6\" class=\"data row5 col6\" >3698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44e34_level0_row6\" class=\"row_heading level0 row6\" >Instance 7</th>\n",
       "      <td id=\"T_44e34_row6_col0\" class=\"data row6 col0\" >3921</td>\n",
       "      <td id=\"T_44e34_row6_col1\" class=\"data row6 col1\" >3888</td>\n",
       "      <td id=\"T_44e34_row6_col2\" class=\"data row6 col2\" >3945</td>\n",
       "      <td id=\"T_44e34_row6_col3\" class=\"data row6 col3\" >4134</td>\n",
       "      <td id=\"T_44e34_row6_col4\" class=\"data row6 col4\" >4306</td>\n",
       "      <td id=\"T_44e34_row6_col5\" class=\"data row6 col5\" >3988</td>\n",
       "      <td id=\"T_44e34_row6_col6\" class=\"data row6 col6\" >3716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44e34_level0_row7\" class=\"row_heading level0 row7\" >Instance 8</th>\n",
       "      <td id=\"T_44e34_row7_col0\" class=\"data row7 col0\" >3942</td>\n",
       "      <td id=\"T_44e34_row7_col1\" class=\"data row7 col1\" >3891</td>\n",
       "      <td id=\"T_44e34_row7_col2\" class=\"data row7 col2\" >4035</td>\n",
       "      <td id=\"T_44e34_row7_col3\" class=\"data row7 col3\" >4283</td>\n",
       "      <td id=\"T_44e34_row7_col4\" class=\"data row7 col4\" >4318</td>\n",
       "      <td id=\"T_44e34_row7_col5\" class=\"data row7 col5\" >4064</td>\n",
       "      <td id=\"T_44e34_row7_col6\" class=\"data row7 col6\" >3709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44e34_level0_row8\" class=\"row_heading level0 row8\" >Instance 9</th>\n",
       "      <td id=\"T_44e34_row8_col0\" class=\"data row8 col0\" >3921</td>\n",
       "      <td id=\"T_44e34_row8_col1\" class=\"data row8 col1\" >3953</td>\n",
       "      <td id=\"T_44e34_row8_col2\" class=\"data row8 col2\" >3999</td>\n",
       "      <td id=\"T_44e34_row8_col3\" class=\"data row8 col3\" >4219</td>\n",
       "      <td id=\"T_44e34_row8_col4\" class=\"data row8 col4\" >4547</td>\n",
       "      <td id=\"T_44e34_row8_col5\" class=\"data row8 col5\" >4022</td>\n",
       "      <td id=\"T_44e34_row8_col6\" class=\"data row8 col6\" >3765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44e34_level0_row9\" class=\"row_heading level0 row9\" >Instance 10</th>\n",
       "      <td id=\"T_44e34_row9_col0\" class=\"data row9 col0\" >3919</td>\n",
       "      <td id=\"T_44e34_row9_col1\" class=\"data row9 col1\" >3916</td>\n",
       "      <td id=\"T_44e34_row9_col2\" class=\"data row9 col2\" >3982</td>\n",
       "      <td id=\"T_44e34_row9_col3\" class=\"data row9 col3\" >4264</td>\n",
       "      <td id=\"T_44e34_row9_col4\" class=\"data row9 col4\" >4197</td>\n",
       "      <td id=\"T_44e34_row9_col5\" class=\"data row9 col5\" >3991</td>\n",
       "      <td id=\"T_44e34_row9_col6\" class=\"data row9 col6\" >3777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f2ffb72090>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(instances_50_20, makes_spans_50_20, study_ga, study_sa, cds, palmer, neh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "100 jobs 5 machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [02:35<27:35,  3.62s/it]  \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [01:42<18:14,  2.40s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [02:29<26:26,  3.47s/it]  \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [12:51<2:16:42, 17.95s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [02:32<27:03,  3.55s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [03:40<39:01,  5.12s/it]  \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [02:11<23:13,  3.05s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [03:12<34:10,  4.49s/it]   \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [05:46<1:01:21,  8.06s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [03:55<41:44,  5.48s/it]   \n"
     ]
    }
   ],
   "source": [
    "instances_100_5 = load_tai(100,5)\n",
    "makes_spans_100_5 = []\n",
    "for instance in instances_100_5:\n",
    "    saga = LSAGA(instance, variety_degree=5)\n",
    "    saga.optim(T_min=0.01)\n",
    "    makes_spans_100_5.append(saga.make_span_star)\n",
    "with open(\"lsaga_makes_spans_100_5.txt\",\"w\") as f:\n",
    "    for make_span in makes_spans_50_20:\n",
    "        f.write(str(make_span)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing heursitics\n",
      "tuning simulated annealing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 5505: 100%|██████████| 10/10 [00:04<00:00,  2.44it/s]\n",
      "Best trial: 1. Best value: 5316: 100%|██████████| 10/10 [00:03<00:00,  3.11it/s]\n",
      "Best trial: 6. Best value: 5287: 100%|██████████| 10/10 [00:05<00:00,  1.76it/s]\n",
      "Best trial: 6. Best value: 5044: 100%|██████████| 10/10 [00:04<00:00,  2.11it/s]\n",
      "Best trial: 3. Best value: 5311: 100%|██████████| 10/10 [00:03<00:00,  3.28it/s]\n",
      "Best trial: 0. Best value: 5174: 100%|██████████| 10/10 [00:04<00:00,  2.04it/s]\n",
      "Best trial: 1. Best value: 5305: 100%|██████████| 10/10 [00:04<00:00,  2.46it/s]\n",
      "Best trial: 9. Best value: 5148: 100%|██████████| 10/10 [00:04<00:00,  2.09it/s]\n",
      "Best trial: 6. Best value: 5506: 100%|██████████| 10/10 [00:02<00:00,  4.37it/s]\n",
      "Best trial: 3. Best value: 5347: 100%|██████████| 10/10 [00:04<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning genetic algorithm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 5493: 100%|██████████| 10/10 [01:11<00:00,  7.16s/it]\n",
      "Best trial: 0. Best value: 5316: 100%|██████████| 10/10 [01:02<00:00,  6.26s/it]\n",
      "Best trial: 7. Best value: 5221: 100%|██████████| 10/10 [01:29<00:00,  8.98s/it]\n",
      "Best trial: 7. Best value: 5043: 100%|██████████| 10/10 [00:42<00:00,  4.27s/it]\n",
      "Best trial: 2. Best value: 5255: 100%|██████████| 10/10 [00:25<00:00,  2.58s/it]\n",
      "Best trial: 7. Best value: 5145: 100%|██████████| 10/10 [00:47<00:00,  4.74s/it]\n",
      "Best trial: 1. Best value: 5283: 100%|██████████| 10/10 [01:26<00:00,  8.66s/it]\n",
      "Best trial: 0. Best value: 5144: 100%|██████████| 10/10 [00:36<00:00,  3.67s/it]\n",
      "Best trial: 9. Best value: 5492: 100%|██████████| 10/10 [02:44<00:00, 16.40s/it]\n",
      "Best trial: 7. Best value: 5367: 100%|██████████| 10/10 [01:12<00:00,  7.24s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"executing heursitics\")\n",
    "cds, palmer, neh = exec_heur(instances_100_5)\n",
    "print(\"tuning simulated annealing\")\n",
    "study_sa = exec_sa(instances_100_5)\n",
    "print(\"tuning genetic algorithm\")\n",
    "study_ga = exec_ga(instances_100_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a4272  {\n",
       "  min-width: 110px;\n",
       "}\n",
       "#T_a4272 th {\n",
       "  min-width: 110px;\n",
       "}\n",
       "#T_a4272_row0_col0, #T_a4272_row0_col1, #T_a4272_row1_col0, #T_a4272_row2_col0, #T_a4272_row3_col0, #T_a4272_row4_col1, #T_a4272_row5_col0, #T_a4272_row6_col0, #T_a4272_row6_col1, #T_a4272_row7_col0, #T_a4272_row8_col0, #T_a4272_row9_col0 {\n",
       "  color: green;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_a4272_row0_col4, #T_a4272_row1_col3, #T_a4272_row2_col3, #T_a4272_row3_col3, #T_a4272_row4_col3, #T_a4272_row5_col4, #T_a4272_row6_col3, #T_a4272_row7_col3, #T_a4272_row8_col3, #T_a4272_row9_col3 {\n",
       "  color: red;\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a4272\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a4272_level0_col0\" class=\"col_heading level0 col0\" >LSAGA</th>\n",
       "      <th id=\"T_a4272_level0_col1\" class=\"col_heading level0 col1\" >Genetic Algorithm</th>\n",
       "      <th id=\"T_a4272_level0_col2\" class=\"col_heading level0 col2\" >Simmulated annealing</th>\n",
       "      <th id=\"T_a4272_level0_col3\" class=\"col_heading level0 col3\" >CDS</th>\n",
       "      <th id=\"T_a4272_level0_col4\" class=\"col_heading level0 col4\" >Palmer</th>\n",
       "      <th id=\"T_a4272_level0_col5\" class=\"col_heading level0 col5\" >NEH</th>\n",
       "      <th id=\"T_a4272_level0_col6\" class=\"col_heading level0 col6\" >Upper bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a4272_level0_row0\" class=\"row_heading level0 row0\" >Instance 1</th>\n",
       "      <td id=\"T_a4272_row0_col0\" class=\"data row0 col0\" >5493</td>\n",
       "      <td id=\"T_a4272_row0_col1\" class=\"data row0 col1\" >5493</td>\n",
       "      <td id=\"T_a4272_row0_col2\" class=\"data row0 col2\" >5505</td>\n",
       "      <td id=\"T_a4272_row0_col3\" class=\"data row0 col3\" >5602</td>\n",
       "      <td id=\"T_a4272_row0_col4\" class=\"data row0 col4\" >5749</td>\n",
       "      <td id=\"T_a4272_row0_col5\" class=\"data row0 col5\" >5538</td>\n",
       "      <td id=\"T_a4272_row0_col6\" class=\"data row0 col6\" >5493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4272_level0_row1\" class=\"row_heading level0 row1\" >Instance 2</th>\n",
       "      <td id=\"T_a4272_row1_col0\" class=\"data row1 col0\" >5299</td>\n",
       "      <td id=\"T_a4272_row1_col1\" class=\"data row1 col1\" >5316</td>\n",
       "      <td id=\"T_a4272_row1_col2\" class=\"data row1 col2\" >5316</td>\n",
       "      <td id=\"T_a4272_row1_col3\" class=\"data row1 col3\" >5548</td>\n",
       "      <td id=\"T_a4272_row1_col4\" class=\"data row1 col4\" >5316</td>\n",
       "      <td id=\"T_a4272_row1_col5\" class=\"data row1 col5\" >5379</td>\n",
       "      <td id=\"T_a4272_row1_col6\" class=\"data row1 col6\" >5268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4272_level0_row2\" class=\"row_heading level0 row2\" >Instance 3</th>\n",
       "      <td id=\"T_a4272_row2_col0\" class=\"data row2 col0\" >5212</td>\n",
       "      <td id=\"T_a4272_row2_col1\" class=\"data row2 col1\" >5221</td>\n",
       "      <td id=\"T_a4272_row2_col2\" class=\"data row2 col2\" >5287</td>\n",
       "      <td id=\"T_a4272_row2_col3\" class=\"data row2 col3\" >5452</td>\n",
       "      <td id=\"T_a4272_row2_col4\" class=\"data row2 col4\" >5325</td>\n",
       "      <td id=\"T_a4272_row2_col5\" class=\"data row2 col5\" >5306</td>\n",
       "      <td id=\"T_a4272_row2_col6\" class=\"data row2 col6\" >5175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4272_level0_row3\" class=\"row_heading level0 row3\" >Instance 4</th>\n",
       "      <td id=\"T_a4272_row3_col0\" class=\"data row3 col0\" >5032</td>\n",
       "      <td id=\"T_a4272_row3_col1\" class=\"data row3 col1\" >5043</td>\n",
       "      <td id=\"T_a4272_row3_col2\" class=\"data row3 col2\" >5044</td>\n",
       "      <td id=\"T_a4272_row3_col3\" class=\"data row3 col3\" >5273</td>\n",
       "      <td id=\"T_a4272_row3_col4\" class=\"data row3 col4\" >5049</td>\n",
       "      <td id=\"T_a4272_row3_col5\" class=\"data row3 col5\" >5114</td>\n",
       "      <td id=\"T_a4272_row3_col6\" class=\"data row3 col6\" >5014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4272_level0_row4\" class=\"row_heading level0 row4\" >Instance 5</th>\n",
       "      <td id=\"T_a4272_row4_col0\" class=\"data row4 col0\" >5267</td>\n",
       "      <td id=\"T_a4272_row4_col1\" class=\"data row4 col1\" >5255</td>\n",
       "      <td id=\"T_a4272_row4_col2\" class=\"data row4 col2\" >5311</td>\n",
       "      <td id=\"T_a4272_row4_col3\" class=\"data row4 col3\" >5484</td>\n",
       "      <td id=\"T_a4272_row4_col4\" class=\"data row4 col4\" >5317</td>\n",
       "      <td id=\"T_a4272_row4_col5\" class=\"data row4 col5\" >5328</td>\n",
       "      <td id=\"T_a4272_row4_col6\" class=\"data row4 col6\" >5250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4272_level0_row5\" class=\"row_heading level0 row5\" >Instance 6</th>\n",
       "      <td id=\"T_a4272_row5_col0\" class=\"data row5 col0\" >5140</td>\n",
       "      <td id=\"T_a4272_row5_col1\" class=\"data row5 col1\" >5145</td>\n",
       "      <td id=\"T_a4272_row5_col2\" class=\"data row5 col2\" >5174</td>\n",
       "      <td id=\"T_a4272_row5_col3\" class=\"data row5 col3\" >5203</td>\n",
       "      <td id=\"T_a4272_row5_col4\" class=\"data row5 col4\" >5274</td>\n",
       "      <td id=\"T_a4272_row5_col5\" class=\"data row5 col5\" >5200</td>\n",
       "      <td id=\"T_a4272_row5_col6\" class=\"data row5 col6\" >5135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4272_level0_row6\" class=\"row_heading level0 row6\" >Instance 7</th>\n",
       "      <td id=\"T_a4272_row6_col0\" class=\"data row6 col0\" >5283</td>\n",
       "      <td id=\"T_a4272_row6_col1\" class=\"data row6 col1\" >5283</td>\n",
       "      <td id=\"T_a4272_row6_col2\" class=\"data row6 col2\" >5305</td>\n",
       "      <td id=\"T_a4272_row6_col3\" class=\"data row6 col3\" >5561</td>\n",
       "      <td id=\"T_a4272_row6_col4\" class=\"data row6 col4\" >5376</td>\n",
       "      <td id=\"T_a4272_row6_col5\" class=\"data row6 col5\" >5351</td>\n",
       "      <td id=\"T_a4272_row6_col6\" class=\"data row6 col6\" >5246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4272_level0_row7\" class=\"row_heading level0 row7\" >Instance 8</th>\n",
       "      <td id=\"T_a4272_row7_col0\" class=\"data row7 col0\" >5137</td>\n",
       "      <td id=\"T_a4272_row7_col1\" class=\"data row7 col1\" >5144</td>\n",
       "      <td id=\"T_a4272_row7_col2\" class=\"data row7 col2\" >5148</td>\n",
       "      <td id=\"T_a4272_row7_col3\" class=\"data row7 col3\" >5387</td>\n",
       "      <td id=\"T_a4272_row7_col4\" class=\"data row7 col4\" >5263</td>\n",
       "      <td id=\"T_a4272_row7_col5\" class=\"data row7 col5\" >5204</td>\n",
       "      <td id=\"T_a4272_row7_col6\" class=\"data row7 col6\" >5106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4272_level0_row8\" class=\"row_heading level0 row8\" >Instance 9</th>\n",
       "      <td id=\"T_a4272_row8_col0\" class=\"data row8 col0\" >5487</td>\n",
       "      <td id=\"T_a4272_row8_col1\" class=\"data row8 col1\" >5492</td>\n",
       "      <td id=\"T_a4272_row8_col2\" class=\"data row8 col2\" >5506</td>\n",
       "      <td id=\"T_a4272_row8_col3\" class=\"data row8 col3\" >5758</td>\n",
       "      <td id=\"T_a4272_row8_col4\" class=\"data row8 col4\" >5606</td>\n",
       "      <td id=\"T_a4272_row8_col5\" class=\"data row8 col5\" >5588</td>\n",
       "      <td id=\"T_a4272_row8_col6\" class=\"data row8 col6\" >5454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a4272_level0_row9\" class=\"row_heading level0 row9\" >Instance 10</th>\n",
       "      <td id=\"T_a4272_row9_col0\" class=\"data row9 col0\" >5338</td>\n",
       "      <td id=\"T_a4272_row9_col1\" class=\"data row9 col1\" >5367</td>\n",
       "      <td id=\"T_a4272_row9_col2\" class=\"data row9 col2\" >5347</td>\n",
       "      <td id=\"T_a4272_row9_col3\" class=\"data row9 col3\" >5708</td>\n",
       "      <td id=\"T_a4272_row9_col4\" class=\"data row9 col4\" >5427</td>\n",
       "      <td id=\"T_a4272_row9_col5\" class=\"data row9 col5\" >5388</td>\n",
       "      <td id=\"T_a4272_row9_col6\" class=\"data row9 col6\" >5328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f296c78c90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(instances_100_5, makes_spans_100_5, study_ga, study_sa, cds, palmer, neh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "100 jobs 10 machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [10:24<1:50:35, 14.52s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [20:21<3:36:26, 28.42s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [25:56<4:35:41, 36.19s/it]  \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [20:02<3:33:01, 27.97s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [05:31<58:44,  7.71s/it]   \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [10:18<1:49:34, 14.39s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [04:37<49:10,  6.46s/it]   \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [12:10<2:09:26, 16.99s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [06:47<1:12:13,  9.48s/it] \n",
      "Temperature 0.01077526366430583:   9%|▊         | 43/500 [08:12<1:27:16, 11.46s/it] \n"
     ]
    }
   ],
   "source": [
    "instances_100_10 = load_tai(100,10)\n",
    "makes_spans_100_10 = []\n",
    "for instance in instances_100_10:\n",
    "    saga = LSAGA(instance, variety_degree=3)\n",
    "    saga.optim(T_min=0.01)\n",
    "    makes_spans_100_10.append(saga.make_span_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing heursitics\n",
      "tuning simulated annealing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 5955: 100%|██████████| 10/10 [00:11<00:00,  1.18s/it]\n",
      "Best trial: 7. Best value: 5536: 100%|██████████| 10/10 [00:08<00:00,  1.12it/s]\n",
      "Best trial: 5. Best value: 5803: 100%|██████████| 10/10 [00:06<00:00,  1.56it/s]\n",
      "Best trial: 2. Best value: 6015: 100%|██████████| 10/10 [00:14<00:00,  1.41s/it]\n",
      "Best trial: 7. Best value: 5766: 100%|██████████| 10/10 [00:11<00:00,  1.16s/it]\n",
      "Best trial: 3. Best value: 5383: 100%|██████████| 10/10 [00:12<00:00,  1.21s/it]\n",
      "Best trial: 5. Best value: 5744: 100%|██████████| 10/10 [00:09<00:00,  1.10it/s]\n",
      "Best trial: 3. Best value: 5881: 100%|██████████| 10/10 [00:06<00:00,  1.62it/s]\n",
      "Best trial: 0. Best value: 6014: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Best trial: 8. Best value: 5987: 100%|██████████| 10/10 [00:06<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning genetic algorithm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 5885: 100%|██████████| 10/10 [03:25<00:00, 20.58s/it]\n",
      "Best trial: 5. Best value: 5503: 100%|██████████| 10/10 [02:59<00:00, 17.93s/it]\n",
      "Best trial: 3. Best value: 5781: 100%|██████████| 10/10 [01:43<00:00, 10.36s/it]\n",
      "Best trial: 3. Best value: 5966: 100%|██████████| 10/10 [02:20<00:00, 14.04s/it]\n",
      "Best trial: 3. Best value: 5636: 100%|██████████| 10/10 [03:27<00:00, 20.73s/it]\n",
      "Best trial: 4. Best value: 5409: 100%|██████████| 10/10 [02:54<00:00, 17.43s/it]\n",
      "Best trial: 2. Best value: 5744: 100%|██████████| 10/10 [01:39<00:00,  9.92s/it]\n",
      "Best trial: 3. Best value: 5776: 100%|██████████| 10/10 [01:32<00:00,  9.24s/it]\n",
      "Best trial: 5. Best value: 5979: 100%|██████████| 10/10 [02:21<00:00, 14.14s/it]\n",
      "Best trial: 2. Best value: 5959: 100%|██████████| 10/10 [02:04<00:00, 12.44s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"executing heursitics\")\n",
    "cds, palmer, neh = exec_heur(instances_100_10)\n",
    "print(\"tuning simulated annealing\")\n",
    "study_sa = exec_sa(instances_100_10)\n",
    "print(\"tuning genetic algorithm\")\n",
    "study_ga = exec_ga(instances_100_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fcaed  {\n",
       "  min-width: 110px;\n",
       "}\n",
       "#T_fcaed th {\n",
       "  min-width: 110px;\n",
       "}\n",
       "#T_fcaed_row0_col1, #T_fcaed_row1_col0, #T_fcaed_row2_col0, #T_fcaed_row3_col0, #T_fcaed_row4_col1, #T_fcaed_row5_col2, #T_fcaed_row6_col0, #T_fcaed_row7_col0, #T_fcaed_row8_col0, #T_fcaed_row8_col1, #T_fcaed_row9_col1 {\n",
       "  color: green;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_fcaed_row0_col3, #T_fcaed_row1_col4, #T_fcaed_row2_col4, #T_fcaed_row3_col3, #T_fcaed_row4_col4, #T_fcaed_row5_col4, #T_fcaed_row6_col4, #T_fcaed_row7_col4, #T_fcaed_row8_col3, #T_fcaed_row9_col3 {\n",
       "  color: red;\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fcaed\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fcaed_level0_col0\" class=\"col_heading level0 col0\" >LSAGA</th>\n",
       "      <th id=\"T_fcaed_level0_col1\" class=\"col_heading level0 col1\" >Genetic Algorithm</th>\n",
       "      <th id=\"T_fcaed_level0_col2\" class=\"col_heading level0 col2\" >Simmulated annealing</th>\n",
       "      <th id=\"T_fcaed_level0_col3\" class=\"col_heading level0 col3\" >CDS</th>\n",
       "      <th id=\"T_fcaed_level0_col4\" class=\"col_heading level0 col4\" >Palmer</th>\n",
       "      <th id=\"T_fcaed_level0_col5\" class=\"col_heading level0 col5\" >NEH</th>\n",
       "      <th id=\"T_fcaed_level0_col6\" class=\"col_heading level0 col6\" >Upper bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fcaed_level0_row0\" class=\"row_heading level0 row0\" >Instance 1</th>\n",
       "      <td id=\"T_fcaed_row0_col0\" class=\"data row0 col0\" >5887</td>\n",
       "      <td id=\"T_fcaed_row0_col1\" class=\"data row0 col1\" >5885</td>\n",
       "      <td id=\"T_fcaed_row0_col2\" class=\"data row0 col2\" >5955</td>\n",
       "      <td id=\"T_fcaed_row0_col3\" class=\"data row0 col3\" >6198</td>\n",
       "      <td id=\"T_fcaed_row0_col4\" class=\"data row0 col4\" >6161</td>\n",
       "      <td id=\"T_fcaed_row0_col5\" class=\"data row0 col5\" >6027</td>\n",
       "      <td id=\"T_fcaed_row0_col6\" class=\"data row0 col6\" >5770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fcaed_level0_row1\" class=\"row_heading level0 row1\" >Instance 2</th>\n",
       "      <td id=\"T_fcaed_row1_col0\" class=\"data row1 col0\" >5428</td>\n",
       "      <td id=\"T_fcaed_row1_col1\" class=\"data row1 col1\" >5503</td>\n",
       "      <td id=\"T_fcaed_row1_col2\" class=\"data row1 col2\" >5536</td>\n",
       "      <td id=\"T_fcaed_row1_col3\" class=\"data row1 col3\" >5851</td>\n",
       "      <td id=\"T_fcaed_row1_col4\" class=\"data row1 col4\" >5889</td>\n",
       "      <td id=\"T_fcaed_row1_col5\" class=\"data row1 col5\" >5569</td>\n",
       "      <td id=\"T_fcaed_row1_col6\" class=\"data row1 col6\" >5349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fcaed_level0_row2\" class=\"row_heading level0 row2\" >Instance 3</th>\n",
       "      <td id=\"T_fcaed_row2_col0\" class=\"data row2 col0\" >5764</td>\n",
       "      <td id=\"T_fcaed_row2_col1\" class=\"data row2 col1\" >5781</td>\n",
       "      <td id=\"T_fcaed_row2_col2\" class=\"data row2 col2\" >5803</td>\n",
       "      <td id=\"T_fcaed_row2_col3\" class=\"data row2 col3\" >6029</td>\n",
       "      <td id=\"T_fcaed_row2_col4\" class=\"data row2 col4\" >6119</td>\n",
       "      <td id=\"T_fcaed_row2_col5\" class=\"data row2 col5\" >5857</td>\n",
       "      <td id=\"T_fcaed_row2_col6\" class=\"data row2 col6\" >5677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fcaed_level0_row3\" class=\"row_heading level0 row3\" >Instance 4</th>\n",
       "      <td id=\"T_fcaed_row3_col0\" class=\"data row3 col0\" >5878</td>\n",
       "      <td id=\"T_fcaed_row3_col1\" class=\"data row3 col1\" >5966</td>\n",
       "      <td id=\"T_fcaed_row3_col2\" class=\"data row3 col2\" >6015</td>\n",
       "      <td id=\"T_fcaed_row3_col3\" class=\"data row3 col3\" >6408</td>\n",
       "      <td id=\"T_fcaed_row3_col4\" class=\"data row3 col4\" >6329</td>\n",
       "      <td id=\"T_fcaed_row3_col5\" class=\"data row3 col5\" >6044</td>\n",
       "      <td id=\"T_fcaed_row3_col6\" class=\"data row3 col6\" >5791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fcaed_level0_row4\" class=\"row_heading level0 row4\" >Instance 5</th>\n",
       "      <td id=\"T_fcaed_row4_col0\" class=\"data row4 col0\" >5670</td>\n",
       "      <td id=\"T_fcaed_row4_col1\" class=\"data row4 col1\" >5636</td>\n",
       "      <td id=\"T_fcaed_row4_col2\" class=\"data row4 col2\" >5766</td>\n",
       "      <td id=\"T_fcaed_row4_col3\" class=\"data row4 col3\" >6018</td>\n",
       "      <td id=\"T_fcaed_row4_col4\" class=\"data row4 col4\" >6070</td>\n",
       "      <td id=\"T_fcaed_row4_col5\" class=\"data row4 col5\" >5807</td>\n",
       "      <td id=\"T_fcaed_row4_col6\" class=\"data row4 col6\" >5468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fcaed_level0_row5\" class=\"row_heading level0 row5\" >Instance 6</th>\n",
       "      <td id=\"T_fcaed_row5_col0\" class=\"data row5 col0\" >5395</td>\n",
       "      <td id=\"T_fcaed_row5_col1\" class=\"data row5 col1\" >5409</td>\n",
       "      <td id=\"T_fcaed_row5_col2\" class=\"data row5 col2\" >5383</td>\n",
       "      <td id=\"T_fcaed_row5_col3\" class=\"data row5 col3\" >5751</td>\n",
       "      <td id=\"T_fcaed_row5_col4\" class=\"data row5 col4\" >5870</td>\n",
       "      <td id=\"T_fcaed_row5_col5\" class=\"data row5 col5\" >5508</td>\n",
       "      <td id=\"T_fcaed_row5_col6\" class=\"data row5 col6\" >5303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fcaed_level0_row6\" class=\"row_heading level0 row6\" >Instance 7</th>\n",
       "      <td id=\"T_fcaed_row6_col0\" class=\"data row6 col0\" >5706</td>\n",
       "      <td id=\"T_fcaed_row6_col1\" class=\"data row6 col1\" >5744</td>\n",
       "      <td id=\"T_fcaed_row6_col2\" class=\"data row6 col2\" >5744</td>\n",
       "      <td id=\"T_fcaed_row6_col3\" class=\"data row6 col3\" >6202</td>\n",
       "      <td id=\"T_fcaed_row6_col4\" class=\"data row6 col4\" >6442</td>\n",
       "      <td id=\"T_fcaed_row6_col5\" class=\"data row6 col5\" >5744</td>\n",
       "      <td id=\"T_fcaed_row6_col6\" class=\"data row6 col6\" >5599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fcaed_level0_row7\" class=\"row_heading level0 row7\" >Instance 8</th>\n",
       "      <td id=\"T_fcaed_row7_col0\" class=\"data row7 col0\" >5750</td>\n",
       "      <td id=\"T_fcaed_row7_col1\" class=\"data row7 col1\" >5776</td>\n",
       "      <td id=\"T_fcaed_row7_col2\" class=\"data row7 col2\" >5881</td>\n",
       "      <td id=\"T_fcaed_row7_col3\" class=\"data row7 col3\" >6146</td>\n",
       "      <td id=\"T_fcaed_row7_col4\" class=\"data row7 col4\" >6168</td>\n",
       "      <td id=\"T_fcaed_row7_col5\" class=\"data row7 col5\" >5938</td>\n",
       "      <td id=\"T_fcaed_row7_col6\" class=\"data row7 col6\" >5623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fcaed_level0_row8\" class=\"row_heading level0 row8\" >Instance 9</th>\n",
       "      <td id=\"T_fcaed_row8_col0\" class=\"data row8 col0\" >5979</td>\n",
       "      <td id=\"T_fcaed_row8_col1\" class=\"data row8 col1\" >5979</td>\n",
       "      <td id=\"T_fcaed_row8_col2\" class=\"data row8 col2\" >6014</td>\n",
       "      <td id=\"T_fcaed_row8_col3\" class=\"data row8 col3\" >6349</td>\n",
       "      <td id=\"T_fcaed_row8_col4\" class=\"data row8 col4\" >6081</td>\n",
       "      <td id=\"T_fcaed_row8_col5\" class=\"data row8 col5\" >6089</td>\n",
       "      <td id=\"T_fcaed_row8_col6\" class=\"data row8 col6\" >5875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fcaed_level0_row9\" class=\"row_heading level0 row9\" >Instance 10</th>\n",
       "      <td id=\"T_fcaed_row9_col0\" class=\"data row9 col0\" >5962</td>\n",
       "      <td id=\"T_fcaed_row9_col1\" class=\"data row9 col1\" >5959</td>\n",
       "      <td id=\"T_fcaed_row9_col2\" class=\"data row9 col2\" >5987</td>\n",
       "      <td id=\"T_fcaed_row9_col3\" class=\"data row9 col3\" >6439</td>\n",
       "      <td id=\"T_fcaed_row9_col4\" class=\"data row9 col4\" >6259</td>\n",
       "      <td id=\"T_fcaed_row9_col5\" class=\"data row9 col5\" >6022</td>\n",
       "      <td id=\"T_fcaed_row9_col6\" class=\"data row9 col6\" >5845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f297626fd0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(instances_100_10, makes_spans_100_10, study_ga, study_sa, cds, palmer, neh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "200 jobs 10 machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Temperature 0.38742048900000015:   2%|▏         | 9/500 [08:27<7:41:04, 56.34s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m instance \u001b[38;5;129;01min\u001b[39;00m instances_200_10:\n\u001b[0;32m      4\u001b[0m     saga \u001b[38;5;241m=\u001b[39m LSAGA(instance, variety_degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     \u001b[43msaga\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     makes_spans_200_10\u001b[38;5;241m.\u001b[39mappend(saga\u001b[38;5;241m.\u001b[39mmake_span_star)\n",
      "Cell \u001b[1;32mIn[6], line 583\u001b[0m, in \u001b[0;36mLSAGA.optim\u001b[1;34m(self, T, T_min, alpha, nb_iter, init_method, neigh_method, length_palier, jump_rate, jump_ratio, debug, trace)\u001b[0m\n\u001b[0;32m    581\u001b[0m new_hps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_neigh_hps(hps, T)\n\u001b[0;32m    582\u001b[0m \u001b[38;5;66;03m#compute the energy difference\u001b[39;00m\n\u001b[1;32m--> 583\u001b[0m neigh_seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenetic_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_hps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    584\u001b[0m neigh_make_span \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_makespan(neigh_seq)\n\u001b[0;32m    585\u001b[0m delta \u001b[38;5;241m=\u001b[39m current_make_span \u001b[38;5;241m-\u001b[39m neigh_make_span\n",
      "Cell \u001b[1;32mIn[6], line 432\u001b[0m, in \u001b[0;36mLSAGA.genetic_algorithm\u001b[1;34m(self, init_type, selection_type, crossover_type, replacement_type, population_size, pool_size, crossover_rate, mutation_rate, num_iterations, max_stagnation, k_points)\u001b[0m\n\u001b[0;32m    429\u001b[0m     child2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmutate(child2, mutation_rate)\n\u001b[0;32m    430\u001b[0m     offspring\u001b[38;5;241m.\u001b[39mextend([child1, child2])\n\u001b[1;32m--> 432\u001b[0m population \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace_population\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplacement_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffspring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopulation_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m population\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_makespan(x))\n\u001b[0;32m    435\u001b[0m current_best_solution \u001b[38;5;241m=\u001b[39m population[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[6], line 386\u001b[0m, in \u001b[0;36mLSAGA.replace_population\u001b[1;34m(self, replacement_type, population, parents, offspring, population_size)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m population_without_parents \u001b[38;5;241m+\u001b[39m combined_sub_population[:\u001b[38;5;28mlen\u001b[39m(parents)]\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_population\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplacement_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moffspring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 364\u001b[0m, in \u001b[0;36mLSAGA.replace_population.<locals>.select_population\u001b[1;34m(selection_type, population, pool_size)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect_population\u001b[39m(selection_type, population, pool_size):\n\u001b[0;32m    353\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;124;03m    Selects individuals for the next population.\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;124;03m        list: Selected individuals for the next population.\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_reproduction_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselection_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 321\u001b[0m, in \u001b[0;36mLSAGA.select_reproduction_pool\u001b[1;34m(self, selection_type, population, pool_size)\u001b[0m\n\u001b[0;32m    318\u001b[0m     chosen \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoices(population_sorted, weights\u001b[38;5;241m=\u001b[39mrank_weights, k\u001b[38;5;241m=\u001b[39mpool_size)\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m selection_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melitist\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 321\u001b[0m     population_sorted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(population, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_makespan)\n\u001b[0;32m    322\u001b[0m     chosen \u001b[38;5;241m=\u001b[39m population_sorted[:pool_size]\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m selection_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtournament\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "Cell \u001b[1;32mIn[6], line 87\u001b[0m, in \u001b[0;36mLSAGA.evaluate_makespan\u001b[1;34m(self, schedule)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_makespan\u001b[39m(\u001b[38;5;28mself\u001b[39m, schedule):\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# Evaluates the makespan (completion time) of a given schedule.\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m     cumulative \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumulate_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschedule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cumulative[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[6], line 81\u001b[0m, in \u001b[0;36mLSAGA.cumulate_seq\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m     79\u001b[0m cumulated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m seq:\n\u001b[1;32m---> 81\u001b[0m     cumulated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumulate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcumulated\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cumulated\n",
      "Cell \u001b[1;32mIn[6], line 73\u001b[0m, in \u001b[0;36mLSAGA.cumulate\u001b[1;34m(self, job, previous_cumul)\u001b[0m\n\u001b[0;32m     71\u001b[0m     res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m previous_cumul[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m job[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(job)):\n\u001b[1;32m---> 73\u001b[0m         res[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(res[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m], previous_cumul[i]) \u001b[38;5;241m+\u001b[39m job[i]\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "instances_200_10 = load_tai(200,10)\n",
    "makes_spans_200_10 = []\n",
    "for instance in instances_200_10:\n",
    "    saga = LSAGA(instance, variety_degree=5)\n",
    "    saga.optim(T_min=0.01)\n",
    "    makes_spans_200_10.append(saga.make_span_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"executing heursitics\")\n",
    "cds, palmer, neh = exec_heur(instances_200_10)\n",
    "print(\"tuning simulated annealing\")\n",
    "study_sa = exec_sa(instances_200_10)\n",
    "print(\"tuning genetic algorithm\")\n",
    "study_ga = exec_ga(instances_200_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "200 jobs 20 machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_200_20 = load_tai(200,20)\n",
    "makes_spans_200_20 = []\n",
    "for instance in instances_20_20:\n",
    "    saga = LSAGA(instance, variety_degree=3)\n",
    "    saga.optim(T_min=0.01)\n",
    "    makes_spans_200_20.append(saga.make_span_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"executing heursitics\")\n",
    "cds, palmer, neh = exec_heur(instances_200_20)\n",
    "print(\"tuning simulated annealing\")\n",
    "study_sa = exec_sa(instances_200_20)\n",
    "print(\"tuning genetic algorithm\")\n",
    "study_ga = exec_ga(instances_200_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "500 jobs 20 machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_500_20 = load_tai(500,20)\n",
    "makes_spans_500_20 = []\n",
    "for instance in instances_500_20:\n",
    "    saga = LSAGA(instance, variety_degree=3)\n",
    "    saga.optim(T_min=0.01)\n",
    "    makes_spans_500_20.append(saga.make_span_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"executing heursitics\")\n",
    "cds, palmer, neh = exec_heur(instances_500_20)\n",
    "print(\"tuning simulated annealing\")\n",
    "study_sa = exec_sa(instances_500_20)\n",
    "print(\"tuning genetic algorithm\")\n",
    "study_ga = exec_ga(instances_500_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High level hyper-parameter study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_saga(instances, n_trials=10):\n",
    "\n",
    "    studies = []\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "    for i, instance in enumerate(instances):\n",
    "        study = optuna.create_study()\n",
    "        \n",
    "        def objective(trial):\n",
    "            variety_degree = trial.suggest_categorical(\"variety_degree\",[0, 1, 3, 5, 8])\n",
    "            lsaga = LSAGA(instance,\n",
    "                       variety_degree=variety_degree)\n",
    "            \n",
    "            lsaga.optim()\n",
    "            return saga.make_span_star\n",
    "        \n",
    "        study.optimize(objective, n_trials, show_progress_bar=True)\n",
    "        studies.append(copy.deepcopy(study))\n",
    "\n",
    "    return studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Temperature 0.0010611166119964739:  13%|█▎        | 65/500 [02:35<17:17,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "instances = load_tai(20,5)\n",
    "lsaga = LSAGA(instances[8], variety_degree=10)\n",
    "lsaga.optim()\n",
    "print(lsaga.make_span_star)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aivenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
